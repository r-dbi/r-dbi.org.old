[
  {
    "objectID": "backends/index.html",
    "href": "backends/index.html",
    "title": "Backends for R-DBI",
    "section": "",
    "text": "Do you maintain a backend and think that yours should be on this list? Please open an issue in the backends repository."
  },
  {
    "objectID": "backends/index.html#azurekusto-1.1.2-2023-03-17",
    "href": "backends/index.html#azurekusto-1.1.2-2023-03-17",
    "title": "Backends for R-DBI",
    "section": "AzureKusto 1.1.2 (2023-03-17) 🔗 🐛",
    "text": "AzureKusto 1.1.2 (2023-03-17) 🔗 🐛\nInterface to ‘Kusto’/‘Azure Data Explorer’\nAn interface to ‘Azure Data Explorer’, also known as ‘Kusto’, a fast, highly scalable data exploration service from Microsoft: https://azure.microsoft.com/en-us/products/data-explorer/. Includes ‘DBI’ and ‘dplyr’ interfaces, with the latter modelled after the ‘dbplyr’ package, whereby queries are translated from R into the native ‘KQL’ query language and executed lazily. On the admin side, the package extends the object framework provided by ‘AzureRMR’ to support creation and deletion of databases, and management of database principals. Part of the ‘AzureR’ family of packages.\nMaintainer: Alex Kyllo jekyllo@microsoft.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#bigrquery-1.4.2-2023-04-20",
    "href": "backends/index.html#bigrquery-1.4.2-2023-04-20",
    "title": "Backends for R-DBI",
    "section": "bigrquery 1.4.2 (2023-04-20) 🔗 🐛",
    "text": "bigrquery 1.4.2 (2023-04-20) 🔗 🐛\nAn Interface to Google’s ‘BigQuery’ ‘API’\nEasily talk to Google’s ‘BigQuery’ database from R.\nMaintainer: Hadley Wickham hadley@posit.co. License: GPL-3"
  },
  {
    "objectID": "backends/index.html#ckanr-0.7.0-2023-03-17",
    "href": "backends/index.html#ckanr-0.7.0-2023-03-17",
    "title": "Backends for R-DBI",
    "section": "ckanr 0.7.0 (2023-03-17) 🔗 🐛",
    "text": "ckanr 0.7.0 (2023-03-17) 🔗 🐛\nClient for the Comprehensive Knowledge Archive Network (‘CKAN’) API\nClient for ‘CKAN’ API (https://ckan.org/). Includes interface to ‘CKAN’ ‘APIs’ for search, list, show for packages, organizations, and resources. In addition, provides an interface to the ‘datastore’ API.\nMaintainer: Francisco Alves fjunior.alves.oliveira@gmail.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#clickhousehttp-0.3.2-2023-07-04",
    "href": "backends/index.html#clickhousehttp-0.3.2-2023-07-04",
    "title": "Backends for R-DBI",
    "section": "ClickHouseHTTP 0.3.2 (2023-07-04) 🐛",
    "text": "ClickHouseHTTP 0.3.2 (2023-07-04) 🐛\nA Simple HTTP Database Interface to ‘ClickHouse’\n‘ClickHouse’ (https://clickhouse.com/) is an open-source, high performance columnar OLAP (online analytical processing of queries) database management system for real-time analytics using SQL. This ‘DBI’ backend relies on the ‘ClickHouse’ HTTP interface and support HTTPS protocol.\nMaintainer: Patrice Godard patrice.godard@gmail.com. License: GPL-3"
  },
  {
    "objectID": "backends/index.html#connections-0.1.1-2020-02-07",
    "href": "backends/index.html#connections-0.1.1-2020-02-07",
    "title": "Backends for R-DBI",
    "section": "connections 0.1.1 (2020-02-07) 🐛",
    "text": "connections 0.1.1 (2020-02-07) 🐛\nIntegrates with the ‘RStudio’ Connections Pane and ‘pins’\nEnables ‘DBI’ compliant packages to integrate with the ‘RStudio’ connections pane, and the ‘pins’ package. It automates the display of schemata, tables, views, as well as the preview of the table’s top 1000 records.\nMaintainer: Javier Luraschi javier@rstudio.com. License: GPL-3"
  },
  {
    "objectID": "backends/index.html#databaseconnector-6.2.3-2023-06-29",
    "href": "backends/index.html#databaseconnector-6.2.3-2023-06-29",
    "title": "Backends for R-DBI",
    "section": "DatabaseConnector 6.2.3 (2023-06-29) 🔗 🐛",
    "text": "DatabaseConnector 6.2.3 (2023-06-29) 🔗 🐛\nConnecting to Various Database Platforms\nAn R ‘DataBase Interface’ (‘DBI’) compatible interface to various database platforms (‘PostgreSQL’, ‘Oracle’, ‘Microsoft SQL Server’, ‘Amazon Redshift’, ‘Microsoft Parallel Database Warehouse’, ‘IBM Netezza’, ‘Apache Impala’, ‘Google BigQuery’, ‘Snowflake’, ‘Spark’, and ‘SQLite’). Also includes support for fetching data as ‘Andromeda’ objects. Uses either ‘Java Database Connectivity’ (‘JDBC’) or other ‘DBI’ drivers to connect to databases.\nMaintainer: Martijn Schuemie schuemie@ohdsi.org. License: Apache License"
  },
  {
    "objectID": "backends/index.html#dbi.rodbc-0.1-2",
    "href": "backends/index.html#dbi.rodbc-0.1-2",
    "title": "Backends for R-DBI",
    "section": "DBI.RODBC 0.1-2",
    "text": "DBI.RODBC 0.1-2\nDBI front-end to RODBC\nA simple DBI front-end to the RODBC package. This package uses version 4 style classes and methods to create a front-end to the existing RODBC (version 0.8-3) package.\nMaintainer: David A. James dj@bell-labs.com. License: GPL (version 2 or later)"
  },
  {
    "objectID": "backends/index.html#dbi.rpgsql-0.1-2",
    "href": "backends/index.html#dbi.rpgsql-0.1-2",
    "title": "Backends for R-DBI",
    "section": "DBI.RPgSQL 0.1-2",
    "text": "DBI.RPgSQL 0.1-2\nDBI front-end to RPgSQL\nA simple DBI front-end to the RPgSQL package. This package uses version 4 style classes and methods to create a front-end to the existing RPgSQL (version 1.0-0) package.\nMaintainer: David A. James dj@bell-labs.com. License: GPL (version 2 or later)"
  },
  {
    "objectID": "backends/index.html#dittodb-0.1.6-2023-04-17",
    "href": "backends/index.html#dittodb-0.1.6-2023-04-17",
    "title": "Backends for R-DBI",
    "section": "dittodb 0.1.6 (2023-04-17) 🔗 🐛",
    "text": "dittodb 0.1.6 (2023-04-17) 🔗 🐛\nA Test Environment for Database Requests\nTesting and documenting code that communicates with remote databases can be painful. Although the interaction with R is usually relatively simple (e.g. data(frames) passed to and from a database), because they rely on a separate service and the data there, testing them can be difficult to set up, unsustainable in a continuous integration environment, or impossible without replicating an entire production cluster. This package addresses that by allowing you to make recordings from your database interactions and then play them back while testing (or in other contexts) all without needing to spin up or have access to the database your code would typically connect to.\nMaintainer: Jonathan Keane jkeane@gmail.com. License: Apache License (&gt;= 2.0)"
  },
  {
    "objectID": "backends/index.html#duckdb-0.8.1-2023-06-16",
    "href": "backends/index.html#duckdb-0.8.1-2023-06-16",
    "title": "Backends for R-DBI",
    "section": "duckdb 0.8.1 (2023-06-16) 🔗 🐛",
    "text": "duckdb 0.8.1 (2023-06-16) 🔗 🐛\nDBI Package for the DuckDB Database Management System\nThe DuckDB project is an embedded analytical data management system with support for the Structured Query Language (SQL). This package includes all of DuckDB and a R Database Interface (DBI) connector.\nMaintainer: Hannes Mühleisen hannes@cwi.nl. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#implyr-0.4.0-2021-03-29",
    "href": "backends/index.html#implyr-0.4.0-2021-03-29",
    "title": "Backends for R-DBI",
    "section": "implyr 0.4.0 (2021-03-29) 🐛",
    "text": "implyr 0.4.0 (2021-03-29) 🐛\nR Interface for Apache Impala\n‘SQL’ back-end to ‘dplyr’ for Apache Impala, the massively parallel processing query engine for Apache ‘Hadoop’. Impala enables low-latency ‘SQL’ queries on data stored in the ‘Hadoop’ Distributed File System ‘(HDFS)’, Apache ‘HBase’, Apache ‘Kudu’, Amazon Simple Storage Service ‘(S3)’, Microsoft Azure Data Lake Store ‘(ADLS)’, and Dell ‘EMC’ ‘Isilon’. See https://impala.apache.org for more information about Impala.\nMaintainer: Ian Cook ianmcook@gmail.com. License: Apache License 2.0 | file LICENSE"
  },
  {
    "objectID": "backends/index.html#lazysf-0.1.0-2020-11-14",
    "href": "backends/index.html#lazysf-0.1.0-2020-11-14",
    "title": "Backends for R-DBI",
    "section": "lazysf 0.1.0 (2020-11-14) 🐛",
    "text": "lazysf 0.1.0 (2020-11-14) 🐛\nDelayed Read for ‘GDAL’ Vector Data Sources\nLazy read for drawings. A ‘dplyr’ back end for data sources supported by ‘GDAL’ vector drivers, that allows working with local or remote sources as if they are in-memory data frames. Basic features works with any drawing format (‘GDAL vector data source’) supported by the ‘sf’ package.\nMaintainer: Michael Sumner mdsumner@gmail.com. License: GPL-3"
  },
  {
    "objectID": "backends/index.html#monetdb.r-2.0.0-2020-08-14",
    "href": "backends/index.html#monetdb.r-2.0.0-2020-08-14",
    "title": "Backends for R-DBI",
    "section": "MonetDB.R 2.0.0 (2020-08-14)",
    "text": "MonetDB.R 2.0.0 (2020-08-14)\nConnect MonetDB to R\nAllows to pull data from MonetDB into R.\nMaintainer: Mitchell Weggemans mitchell.weggemans@monetdbsolutions.com. License: MPL (== 2.0)"
  },
  {
    "objectID": "backends/index.html#monetdblite-0.6.0-2018-07-27",
    "href": "backends/index.html#monetdblite-0.6.0-2018-07-27",
    "title": "Backends for R-DBI",
    "section": "MonetDBLite 0.6.0 (2018-07-27) 🐛",
    "text": "MonetDBLite 0.6.0 (2018-07-27) 🐛\nIn-Process Version of ‘MonetDB’\nAn in-process version of ‘MonetDB’, a SQL database designed for analytical tasks. Similar to ‘SQLite’, the database runs entirely inside the ‘R’ shell.\nMaintainer: Hannes Mühleisen hannes@cwi.nl. License: MPL (== 2.0)"
  },
  {
    "objectID": "backends/index.html#noctua-2.6.1-2022-12-20",
    "href": "backends/index.html#noctua-2.6.1-2022-12-20",
    "title": "Backends for R-DBI",
    "section": "noctua 2.6.1 (2022-12-20) 🐛",
    "text": "noctua 2.6.1 (2022-12-20) 🐛\nConnect to ‘AWS Athena’ using R ‘AWS SDK’ ‘paws’ (‘DBI’ Interface)\nDesigned to be compatible with the ‘R’ package ‘DBI’ (Database Interface) when connecting to Amazon Web Service (‘AWS’) Athena https://aws.amazon.com/athena/. To do this the ‘R’ ‘AWS’ Software Development Kit (‘SDK’) ‘paws’ https://github.com/paws-r/paws is used as a driver.\nMaintainer: Dyfan Jones dyfan.r.jones@gmail.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#odbc-1.3.5-2023-06-29",
    "href": "backends/index.html#odbc-1.3.5-2023-06-29",
    "title": "Backends for R-DBI",
    "section": "odbc 1.3.5 (2023-06-29) 🔗 🔗 🐛",
    "text": "odbc 1.3.5 (2023-06-29) 🔗 🔗 🐛\nConnect to ODBC Compatible Databases (using the DBI Interface)\nA DBI-compatible interface to ODBC databases.\nMaintainer: Hadley Wickham hadley@rstudio.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#pool-1.0.1-2023-02-21",
    "href": "backends/index.html#pool-1.0.1-2023-02-21",
    "title": "Backends for R-DBI",
    "section": "pool 1.0.1 (2023-02-21) 🔗 🐛",
    "text": "pool 1.0.1 (2023-02-21) 🔗 🐛\nObject Pooling\nEnables the creation of object pools, which make it less computationally expensive to fetch a new object. Currently the only supported pooled objects are ‘DBI’ connections.\nMaintainer: Hadley Wickham hadley@posit.co. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rathena-2.6.1-2022-12-20",
    "href": "backends/index.html#rathena-2.6.1-2022-12-20",
    "title": "Backends for R-DBI",
    "section": "RAthena 2.6.1 (2022-12-20) 🐛",
    "text": "RAthena 2.6.1 (2022-12-20) 🐛\nConnect to ‘AWS Athena’ using ‘Boto3’ (‘DBI’ Interface)\nDesigned to be compatible with the R package ‘DBI’ (Database Interface) when connecting to Amazon Web Service (‘AWS’) Athena https://aws.amazon.com/athena/. To do this ‘Python’ ‘Boto3’ Software Development Kit (‘SDK’) https://boto3.amazonaws.com/v1/documentation/api/latest/index.html is used as a driver.\nMaintainer: Dyfan Jones dyfan.r.jones@gmail.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rclickhouse-0.6.7-2023-04-02",
    "href": "backends/index.html#rclickhouse-0.6.7-2023-04-02",
    "title": "Backends for R-DBI",
    "section": "RClickhouse 0.6.7 (2023-04-02) 🐛",
    "text": "RClickhouse 0.6.7 (2023-04-02) 🐛\n‘Yandex Clickhouse’ Interface for R with Basic ‘dplyr’ Support\n‘Yandex Clickhouse’ (https://clickhouse.com/) is a high-performance relational column-store database to enable big data exploration and ‘analytics’ scaling to petabytes of data. Methods are provided that enable working with ‘Yandex Clickhouse’ databases via ‘DBI’ methods and using ‘dplyr’/‘dbplyr’ idioms.\nMaintainer: Christian Hotz-Behofsits christian.hotz-behofsits@wu.ac.at. License: GPL-2"
  },
  {
    "objectID": "backends/index.html#rh2-0.2.4-2018-03-14",
    "href": "backends/index.html#rh2-0.2.4-2018-03-14",
    "title": "Backends for R-DBI",
    "section": "RH2 0.2.4 (2018-03-14)",
    "text": "RH2 0.2.4 (2018-03-14)\nDBI/RJDBC Interface to H2 Database\nDBI/RJDBC interface to h2 database. h2 version 1.3.175 is included.\nMaintainer: “David M. Kaplan” dmkaplan2000@gmail.com. License: Mozilla Public License 1.1"
  },
  {
    "objectID": "backends/index.html#rjdbc-0.2-10-2022-03-24",
    "href": "backends/index.html#rjdbc-0.2-10-2022-03-24",
    "title": "Backends for R-DBI",
    "section": "RJDBC 0.2-10 (2022-03-24)",
    "text": "RJDBC 0.2-10 (2022-03-24)\nProvides Access to Databases Through the JDBC Interface\nThe RJDBC package is an implementation of R’s DBI interface using JDBC as a back-end. This allows R to connect to any DBMS that has a JDBC driver.\nMaintainer: Simon Urbanek Simon.Urbanek@r-project.org. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rmariadb-1.2.2-2022-06-19",
    "href": "backends/index.html#rmariadb-1.2.2-2022-06-19",
    "title": "Backends for R-DBI",
    "section": "RMariaDB 1.2.2 (2022-06-19) 🔗 🔗 🐛",
    "text": "RMariaDB 1.2.2 (2022-06-19) 🔗 🔗 🐛\nDatabase Interface and MariaDB Driver\nImplements a DBI-compliant interface to MariaDB (https://mariadb.org/) and MySQL (https://www.mysql.com/) databases.\nMaintainer: Kirill Müller krlmlr+r@mailbox.org. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rmysql-0.10.25-2022-12-06",
    "href": "backends/index.html#rmysql-0.10.25-2022-12-06",
    "title": "Backends for R-DBI",
    "section": "RMySQL 0.10.25 (2022-12-06) 🐛",
    "text": "RMySQL 0.10.25 (2022-12-06) 🐛\nDatabase Interface and ‘MySQL’ Driver for R\nLegacy ‘DBI’ interface to ‘MySQL’ / ‘MariaDB’ based on old code ported from S-PLUS. A modern ‘MySQL’ client based on ‘Rcpp’ is available from the ‘RMariaDB’ package.\nMaintainer: Jeroen Ooms jeroen@berkeley.edu. License: GPL-2"
  },
  {
    "objectID": "backends/index.html#rodbcdbi-0.1.1-2016-03-14",
    "href": "backends/index.html#rodbcdbi-0.1.1-2016-03-14",
    "title": "Backends for R-DBI",
    "section": "RODBCDBI 0.1.1 (2016-03-14)",
    "text": "RODBCDBI 0.1.1 (2016-03-14)\nProvides Access to Databases Through the ODBC Interface\nAn implementation of R’s DBI interface using ODBC package as a back-end. This allows R to connect to any DBMS that has a ODBC driver.\nMaintainer: Nagi Teramo teramonagi@gmail.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#roracle-1.3-1.1-2021-11-10",
    "href": "backends/index.html#roracle-1.3-1.1-2021-11-10",
    "title": "Backends for R-DBI",
    "section": "ROracle 1.3-1.1 (2021-11-10)",
    "text": "ROracle 1.3-1.1 (2021-11-10)\nOCI Based Oracle Database Interface for R\nOracle Database interface (DBI) driver for R. This is a DBI-compliant Oracle driver based on the OCI.\nMaintainer: Rajendra S. Pingte rajendra.pingte@oracle.com. License: LGPL"
  },
  {
    "objectID": "backends/index.html#rpostgres-1.4.5-2023-01-20",
    "href": "backends/index.html#rpostgres-1.4.5-2023-01-20",
    "title": "Backends for R-DBI",
    "section": "RPostgres 1.4.5 (2023-01-20) 🔗 🐛",
    "text": "RPostgres 1.4.5 (2023-01-20) 🔗 🐛\nRcpp Interface to PostgreSQL\nFully DBI-compliant Rcpp-backed interface to PostgreSQL https://www.postgresql.org/, an open-source relational database.\nMaintainer: Kirill Müller kirill@cynkra.com. License: GPL-3"
  },
  {
    "objectID": "backends/index.html#rpostgresql-0.7-5-2023-02-10",
    "href": "backends/index.html#rpostgresql-0.7-5-2023-02-10",
    "title": "Backends for R-DBI",
    "section": "RPostgreSQL 0.7-5 (2023-02-10) 🔗 🔗",
    "text": "RPostgreSQL 0.7-5 (2023-02-10) 🔗 🔗\nR Interface to the ‘PostgreSQL’ Database System\nDatabase interface and ‘PostgreSQL’ driver for ‘R’. This package provides a Database Interface ‘DBI’ compliant driver for ‘R’ to access ‘PostgreSQL’ database systems. In order to build and install this package from source, ‘PostgreSQL’ itself must be present your system to provide ‘PostgreSQL’ functionality via its libraries and header files. These files are provided as ‘postgresql-devel’ package under some Linux distributions. On ‘macOS’ and ‘Microsoft Windows’ system the attached ‘libpq’ library source will be used.\nMaintainer: Tomoaki Nishiyama tomoakin@staff.kanazawa-u.ac.jp. License: GPL-3 | file LICENSE"
  },
  {
    "objectID": "backends/index.html#rpresto-1.4.5-2023-05-05",
    "href": "backends/index.html#rpresto-1.4.5-2023-05-05",
    "title": "Backends for R-DBI",
    "section": "RPresto 1.4.5 (2023-05-05) 🐛",
    "text": "RPresto 1.4.5 (2023-05-05) 🐛\nDBI Connector to Presto\nImplements a ‘DBI’ compliant interface to Presto. Presto is an open source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes: https://prestodb.io/.\nMaintainer: Jarod G.R. Meng jarodm@fb.com. License: BSD_3_clause + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rredshiftsql-0.1.2-2016-09-15",
    "href": "backends/index.html#rredshiftsql-0.1.2-2016-09-15",
    "title": "Backends for R-DBI",
    "section": "RRedshiftSQL 0.1.2 (2016-09-15)",
    "text": "RRedshiftSQL 0.1.2 (2016-09-15)\nR Interface to the ‘Redshift’ Database\nSuperclasses ‘PostgreSQL’ connection to help enable full ‘dplyr’ functionality on ‘Redshift’.\nMaintainer: Michael Treadwell michael.treadwell@interworks.com. License: GPL-2"
  },
  {
    "objectID": "backends/index.html#rsqlite-2.3.1-2023-04-03",
    "href": "backends/index.html#rsqlite-2.3.1-2023-04-03",
    "title": "Backends for R-DBI",
    "section": "RSQLite 2.3.1 (2023-04-03) 🔗 🐛",
    "text": "RSQLite 2.3.1 (2023-04-03) 🔗 🐛\nSQLite Interface for R\nEmbeds the SQLite database engine in R and provides an interface compliant with the DBI package. The source for the SQLite engine and for various extensions in a recent version is included. System libraries will never be consulted because this package relies on static linking for the plugins it includes; this also ensures a consistent experience across all installations.\nMaintainer: Kirill Müller kirill@cynkra.com. License: LGPL (&gt;= 2.1)"
  },
  {
    "objectID": "backends/index.html#rsqlserver-0.3.0-2017-06-17",
    "href": "backends/index.html#rsqlserver-0.3.0-2017-06-17",
    "title": "Backends for R-DBI",
    "section": "RSQLServer 0.3.0 (2017-06-17) 🐛",
    "text": "RSQLServer 0.3.0 (2017-06-17) 🐛\nSQL Server R Database Interface (DBI) and ‘dplyr’ SQL Backend\nUtilises The ‘jTDS’ project’s ‘JDBC’ 3.0 ‘SQL Server’ driver to extend ‘DBI’ classes and methods. The package also implements a ‘SQL’ backend to the ‘dplyr’ package.\nMaintainer: Imanuel Costigan i.costigan@me.com. License: GPL-2"
  },
  {
    "objectID": "backends/index.html#sergeant-0.9.1-2021-11-29",
    "href": "backends/index.html#sergeant-0.9.1-2021-11-29",
    "title": "Backends for R-DBI",
    "section": "sergeant 0.9.1 (2021-11-29) 🐛",
    "text": "sergeant 0.9.1 (2021-11-29) 🐛\nTools to Transform and Query Data with Apache Drill\nApache Drill is a low-latency distributed query engine designed to enable data exploration and analysis on both relational and non-relational data stores, scaling to petabytes of data. Methods are provided that enable working with Apache Drill instances via the REST API, DBI methods and using ‘dplyr’/‘dbplyr’ idioms. Helper functions are included to facilitate using official Drill Docker images/containers.\nMaintainer: Bob Rudis bob@rud.is. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#sparklyr-1.8.2-2023-07-01",
    "href": "backends/index.html#sparklyr-1.8.2-2023-07-01",
    "title": "Backends for R-DBI",
    "section": "sparklyr 1.8.2 (2023-07-01) 🐛",
    "text": "sparklyr 1.8.2 (2023-07-01) 🐛\nR Interface to Apache Spark\nR interface to Apache Spark, a fast and general engine for big data processing, see https://spark.apache.org/. This package supports connecting to local and remote Apache Spark clusters, provides a ‘dplyr’ compatible back-end, and provides an interface to Spark’s built-in machine learning algorithms.\nMaintainer: Edgar Ruiz edgar@rstudio.com. License: Apache License 2.0 | file LICENSE"
  },
  {
    "objectID": "blog/posts/dbi-3-4.html",
    "href": "blog/posts/dbi-3-4.html",
    "title": "Maintaining DBI, 4/4",
    "section": "",
    "text": "The {DBI} package (database interface) provides an abstraction for communication between R and database management systems (DBMSes) by specifying a common application programming interface (API). Actual connectivity to DBMSes is established via database specific backend packages, implementing this interface. Examples for such backends include RPostgres, RMariaDB, and RSQLite. For users that are new to DBI, the introductory tutorial provides a good entry point for getting acquainted with some key concepts.\nThis blog post summarizes recent developments in {DBI} and related packages and concludes with an outlook on potential future directions. Similar articles are available from previous years, reporting on earlier states of the {DBI} ecosystem:\n\n3/4: January 2021\n2/4: December 2019\n1/4: December 2018"
  },
  {
    "objectID": "blog/posts/dbi-3-4.html#what-is-dbi",
    "href": "blog/posts/dbi-3-4.html#what-is-dbi",
    "title": "Maintaining DBI, 4/4",
    "section": "",
    "text": "The {DBI} package (database interface) provides an abstraction for communication between R and database management systems (DBMSes) by specifying a common application programming interface (API). Actual connectivity to DBMSes is established via database specific backend packages, implementing this interface. Examples for such backends include RPostgres, RMariaDB, and RSQLite. For users that are new to DBI, the introductory tutorial provides a good entry point for getting acquainted with some key concepts.\nThis blog post summarizes recent developments in {DBI} and related packages and concludes with an outlook on potential future directions. Similar articles are available from previous years, reporting on earlier states of the {DBI} ecosystem:\n\n3/4: January 2021\n2/4: December 2019\n1/4: December 2018"
  },
  {
    "objectID": "blog/posts/dbi-3-4.html#recent-developments",
    "href": "blog/posts/dbi-3-4.html#recent-developments",
    "title": "Maintaining DBI, 4/4",
    "section": "Recent developments",
    "text": "Recent developments\nSeveral packages associated with DBI have been updated since early 2021:\n\nDBI 1.1.1 -&gt; 1.1.2 (NEWS)\nRMariaDB 1.1.0 -&gt; 1.2.1 (NEWS)\nRPostgres 1.3.1 -&gt; 1.4.3 (NEWS)\nRSQLite 2.2.2 -&gt; 2.2.9 (NEWS)\nDBItest 1.7.0 -&gt; 1.7.2 (NEWS)\n\nAnd the following sections elaborate on some of the noteworthy changes and improvements contained in these updates, both user-visible and internal.\n\nClickable method documentation\nThe DBI method reference on https://dbi.r-dbi.org/reference/ has been updated to include clickable links to known DBI backends. This makes documentation specific to certain backends more accessible, as optional function arguments used by some backend implementations are only documented by the respective packages.\n\n\nFull support for AWS Redshift\nRedshift support has been greatly improved by Adam Foryś as part of the RPostgres package and both databases now pass all applicable tests offered by DBItest. The BLOB data type is currently not supported by Redshift and consequently, related tests are skipped. For connecting to a Redshift cluster, the RPostgres package exports Redshift() (to be used over Postgres()).\n\n\nFaster table imports\nPrevious versions of {RMariaDB} and {RPostgres} relied dbBind() for writing tables, using a prepared INSERT INTO ... VALUES (...) statement with placeholders. Contrary to the expectation, this was very inefficient, because each row requires a communication roundtrip to the server. To improve the situation, {RMariaDB} now uses LOAD DATA LOCAL INFILE to load data from a temporary CSV file. Recent MySQL server versions disable this capability by default, and therefore it is also disabled by default in {RMariaDB}. If your server supports this, enable fast loading by passing load_data_local_infile = TRUE to dbConnect(). For {RPostgres}, dbAppendTable() has been updated to use the same optimization as dbWriteTable() when writing data.\n\n\nWindows compatibility\n{RMariaDB} can now use the caching_sha2_password plugin on Windows which was permanently disabled on previous versions. This is important for connecting to recent versions of MySQL which require this plugin.\n\n\nExtended data types for SQLite\nThanks to Eric Anderson, {RSQLite} now returns typed data for columns declared with DATE, TIME and TIMESTAMP data types. To enable this feature, extended_types = TRUE has to be passed in dbConnect().\n\n\nInterrupt handling\nThe check_interrupts = TRUE argument to dbConnect() in {RPostgres} now correctly cancels the query and returns to the user as soon as an interrupt is signalled (by pressing Ctrl+C or Escape in RStudio). Thanks to Mateusz Żółtak for tests and discussion.\n\n\nAutomation\n{RMariaDB} is tested against all combinations of major MariaDB and MySQL client/server releases, while {RPostgres} is tested against all versions of PostgreSQL ≥ 10 using GitHub Actions. This guarantees compatibility with a broader range of database instances for both backends and for future updates to the corresponding packages. All tests are run daily, thereby ensuring that upstream updates remain compatible with backend implementations. The database servers are installed on GitHub Actions using dedicated actions for installing MariaDB, MySQL and Postgres, maintained by Andrew Kane.\nThanks to the automated monitoring of SQLite3 releases, the vendored code can be updated continuously with minimal delay over upstream releases. {RSQLite} now uses SQLite3 3.37.0 and became available from CRAN only 10 days after the upstream release.\n\n\nSimpler upgrade path for DBItest\nBy making it possible for backends to specify the supported version of {DBItest}, using tweaks(dbitest_version = \"x.y.z\"), it is now simpler to update {DBItest} on CRAN. Newly added tests in {DBItest} are skipped if the declared version is too low. Skipped tests are reported in the test results and can be fixed independently of the {DBItest} releases.\n\n\nInlined Boost headers\nThe {BH} package is a C++ header-only package containing in excess of 10,000 individual files and installation has proven challenging for some systems, such as Amazon’s Elastic File System. By vendoring only the required files into {RSQLite}, {RMariaDB} and {RPostgres}, it is no longer necessary to install {BH} to use these packages, and therefore the total number of files required to build these packages is greatly reduced. Thanks to RStudio for supporting this change.\n\n\nReorganized structure of the R code\n{DBI} uses S4 classes and generic functions to specify the interface to be implemented by backends, using database specific subclasses. Class specific generic implementations are consequently declared with setMethod(), using the following convention:\nsetMethod(\"foo\", c(\"myclass\", \"character\"), function(x, char_arg, ...) {\n  ...\n})\nInstead of passing an anonymous function as definition argument to setMethod(), this has been changed to a semantic equivalent which is more explicit:\nfoo_myclass_character &lt;- function(x, char_arg, ...) {\n  ...\n}\n\nsetMethod(\"foo\", c(\"myclass\", \"character\"), foo_myclass_mycharacter)\nReasons for this transformation were to make the respective implementations more accessible, as function definitions now can be displayed more easily via mypkg:::foo_myclass_character, and to generally make the code-base easier to read and navigate. In similar spirit, each such generic implementation is now defined in its own file with file names constructed as foo_myclass_mycharacter.R. This makes it immediately clear, exactly which methods are implemented by a package, simply from the list of associated files. Code transformation was carried out in semi-automated fashion, with the help of a script that uses infrastructure from the “Pre-processing R code” project."
  },
  {
    "objectID": "blog/posts/dbi-3-4.html#future-work",
    "href": "blog/posts/dbi-3-4.html#future-work",
    "title": "Maintaining DBI, 4/4",
    "section": "Future work",
    "text": "Future work\nThe {DBI} package provides a low-level interface for database connectivity with a narrow scope. Data query and manipulation tasks that are not in-scope for {DBI} are currently left to auxiliary packages, including dbplyr, dm, dbx and rquery. {DBI} uses S4, one of several systems for object-oriented programming in R. While S4 offers several advantages over its predecessor S3, including increased strictness and multiple dispatch, it also is more rigid compared to S3.   Consequently, once the definition of a generic is published, it is difficult to make changes without breaking downstream dependencies.\nThe first release of {DBI} dates back roughly 20 years and since, the package has been widely adopted by others, both for accessing databases or providing backends to DBMSes. Its success, combined with the rigidity imposed by S4, has made it difficult to extend the interface beyond what is currently offered. When considering new additions, there is pressure to get it right in the first attempt, thereby holding back less essential improvements.\nThe DBI specification in the {DBItest} package aims to standardize the feature set of {DBI}-compliant backends, and to provide a test suite against which conformity of an implementation can be verified. Due to differences in design of individual DBMSes, not all features of the DBI specification and therefore not all tests provided by {DBItest} are supported by all backend packages. Using a newly introduced mechanism, backends can declare, by means of tweaks, which tests to run in what way. This addresses some of the problems associated with implementing a test suite that can be re-used for several backends. General-purpose clients however, can only make guesses as to the exact feature set supported by a given backend or connection. There currently is no formal way to declare certain capabilities as missing (or available).\nBased on these observations, for extending DBI, it may be worthwhile to address the following two issues:\n\nFormal declaration of capabilities.\nDecoupling the user from the backend interface.\n\nThe new dbi3 repository contains a collection of issues, some of which will be easier to address after these changes are in place.\n\nCapabilities\nA mechanism is introduced by which backends can declare explicitly which features of DBI a particular connection supports. Examples for existing functionality that varies over backends include:\n\nSupport for BLOBs (not available e.g. in Redshift).\nSupport for logical columns (not available e.g. in SQL Server or SQLite).\nSupport for named or nested transactions (not standardized).\nPlaceholder character to use in parameterized queries (different across databases).\n\nIn the future, backends may also indicate:\n\nWhether asynchronous queries are supported (important for web development).\nWhether the database supports SQL or a different query language (DBI currently assumes SQL).\n\nThe list of possible capabilities will be maintained by DBI and {DBItest} will rely solely on these capabilities, foregoing the current tweaking mechanism. Users can in turn query these capabilities and act accordingly.\n\n\nSeparate user interface\nAs an evolution of the current approach, where users of DBI will often directly call methods that are mostly implemented by backends themselves, introduction of a separate user-facing API may be worthwhile. Based on plain functions and essentially providing a facade, this user interface would be sufficient for the overwhelming majority of use cases. At the same time, such an approach should contribute to simpler code with less duplication in backend packages.\nThe new user interface performs tasks that are common to all database backends (e.g. validation of arguments), and calls methods provided by the backends, in some cases dependent on declared capabilities. Overall, this should lead to less code that needs to be reimplemented across backends. The decoupling of interfaces could help with iterative improvements, while guaranteeing stability for users. As an example, a dbi_write_table() function that optionally creates and writes data to a database table might encompass the following functionality:\n\nIf the backend supports transactions:\n\nCall dbi_is_transacting() to determine if the statement is occurring as part of a transaction.\nCall dbi_begin_transaction() if it is not already part a transaction.\nUse dbi_begin_transaction(name = \"...\") if the backend supports named transactions.\n\nCall dbi_remove_table() and/or dbi_create_table() if necessary.\nCall dbi_append_table().\nCall dbi_commit() on success or dbi_rollback() on failure whenever transactions are supported.\n\nFor appending rows to a table, dbi_append_table() might check if the backend supports streaming uploads or if SQL should be created for inserting rows. In the latter case, the SQL statement (or multiple statements for large tables) could be constructed using quoted literals obtained from dbi_quote_literal(). The backend could indicate the maximum supported length of a statement, so that splitting of large tables into multiple chunks can happen automatically.\nAs a final example, a backend supporting asynchronous operations might rely entirely on DBI for providing the corresponding blocking operations. The asynchronous procedure provided by the backend could automatically be wrapped by a DBI function that only returns upon completion.\nSuch a split API would allow for generics declared by {DBI} for interfacing with backends to remain frozen. To extend or alter the signature of a generic, a new generic can be added, using some form of versioning (e.g. with a numeric suffix, such as dbAppendTable1(), dbAppendTable2(), etc.). With such an architecture, arguments in generics could be declared explicitly, without relying on forwarding via ..., as is done currently. The user is presented with a stable API with only backward-compatible changes, {DBI} internally decides which versions of a method to call. When a new version of a generic is introduced, {DBI} documents and proposes an upgrade path for backend implementers. In the long run this would also allow for transitioning to another object-oriented system such as S3 or R7 without introducing user-facing breaking changes.\nThis approach also enables support of rich callbacks: each function in the facade can notify listeners on entry and before returning. For example, a call to dbi_connect() would notify interested parties that a new connection has been established, and a call to dbi_query() issues callbacks with the query and the result. Potential use cases include:\n\nLogging as in {dblog}.\nThe Connections pane in RStudio.\nMocking (with hooks) as in {dittodb}.\n\nA versioning scheme could also be implemented for callbacks, keeping existing callbacks frozen while allowing for addition of new features that alter callback signatures."
  },
  {
    "objectID": "blog/posts/dbi-3-4.html#acknowledgments",
    "href": "blog/posts/dbi-3-4.html#acknowledgments",
    "title": "Maintaining DBI, 4/4",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI’d like to thank Jeroen Ooms and Gábor Csárdi for providing crucial infrastructure to support this and many other projects in the R ecosystem.\nThanks to the numerous contributors to the packages in the “Maintaining DBI” project in 2021:\n\nDBI: @bwohl, @cboettig, @dcassol, @jawond, @mmccarthy404, @pnacht, @r2evans, @vituri, and @zoushucai;\nRSQLite: @ablack3, @billy34, @edwindj, @gaborcsardi, @ggrothendieck, @giocomai, @habilzare, @honghh2018, @Jeff-Gui, @kevinushey, @mgirlich, @plantton, @schuemie, @Shicheng-Guo, and @tschoonj;\nRPostgres: @aleaficionado, @armenic, @ateucher, @baderstine, @beralef, @carlganz, @ColinFay, @dcaud, @dpprdan, @f-ritter, @galachad, @GitHubGeniusOverlord, @gontcharovd, @gtm19, @hadley, @jakob-r, @jeroen, @jkylearmstrong, @JSchoenbachler, @matthewgson, @mgirlich, @mmuurr, @mskyttner, @phedinkus, @ppssphysics, @RakeshG1, @rickbpdq, @samiaab1990, @sawnaanwas, @tomasjanikds, @vspinu, @waynelapierre, @zmbc, and @zozlak;\nRMariaDB: @bakiunal, @dirkschumacher, @hadley, @jeroen, @Mosk915, @noamross, @paulmaunders, @retowyss, @rorynolan, @twentytitus, @verajosemanuel, @wiligl, @Woosah, and @zoushucai.\nDBItest: @adamsma, and @michaelquinn32;\n\nThanks also to Nicolas Bennett for reviewing and editing this blog post."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html",
    "href": "blog/posts/dbi-3-2.html",
    "title": "Maintaining DBI, 2/4",
    "section": "",
    "text": "DBI stands for database interface, and DBI is a package for connecting to database management systems (DBMS). The goal of DBI is to provide a common interface for accessing a database, regardless of the specific underlying DBMS.\nDBI works with a variety of DBMS, such as Postgres, MariaDB, and SQLite, allowing users to focus on the specifics of their project instead of setting up the infrastructure for data import and export.\nThe DBI package is perfect for anyone looking to connect to a database, read/write entire tables, and/or execute SQL queries. DBI offers more control to the user than packages such as {dbplyr}.\nThe current version of DBI is 1.1.0. This blog post summarizes recent developments in DBI and related packages."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#what-is-dbi",
    "href": "blog/posts/dbi-3-2.html#what-is-dbi",
    "title": "Maintaining DBI, 2/4",
    "section": "",
    "text": "DBI stands for database interface, and DBI is a package for connecting to database management systems (DBMS). The goal of DBI is to provide a common interface for accessing a database, regardless of the specific underlying DBMS.\nDBI works with a variety of DBMS, such as Postgres, MariaDB, and SQLite, allowing users to focus on the specifics of their project instead of setting up the infrastructure for data import and export.\nThe DBI package is perfect for anyone looking to connect to a database, read/write entire tables, and/or execute SQL queries. DBI offers more control to the user than packages such as {dbplyr}.\nThe current version of DBI is 1.1.0. This blog post summarizes recent developments in DBI and related packages."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#specification-of-immediate-argument-to-dbsendquery-and-friends",
    "href": "blog/posts/dbi-3-2.html#specification-of-immediate-argument-to-dbsendquery-and-friends",
    "title": "Maintaining DBI, 2/4",
    "section": "Specification of immediate argument to dbSendQuery() and friends",
    "text": "Specification of immediate argument to dbSendQuery() and friends\nTom Nolan raised an issue on GitHub, requesting to specify details of the behavior of query execution. It became apparent that the DBI specification did not account for database drivers where the execution path is substantially different for queries with or without parameters. Recent version of DBI mandated the use of a prepared statement or query for everything.\nSimilar problems have been noted in MariaDB, Postgres and SQL Server (when accessed through {odbc}): some statements cannot be executed as prepared statements, or prepared statements are disabled. Over the course of several months, the details of the required extension of this API were fleshed out.\nThe dbSendQuery(), dbGetQuery(), dbSendStatement() and dbExecute() methods gain a new immediate argument. By setting this argument to TRUE, a direct query is created, allowing to execute queries that could not be run previously. Arguably, this is one of those obscure features that are not noted until they are missed.\nIt is up to the individual backends to add support for this argument. The default value should be made backward-compatible with the previous version of DBI 1.0.0. It has already been implemented in the {odbc} package. Plans to implement this feature in both {RMariaDB} and {RPostgres} are underway.\n\nExamples using immediate\nlibrary(DBI)\ncon &lt;- dbConnect(odbc::odbc(), dsn = \"SQLServerConnection\")\n\n# Create local temporary tables:\n# Did not work before, temporary table was removed immediately.\ndbExecute(con, \"CREATE TABLE #temp (a integer)\", immediate = TRUE)\ndbExecute(con, \"INSERT INTO #temp VALUES (1)\", immediate = TRUE)\n\n# Show execution plan:\n# Did not work before, execution plan was never shown\ndbExecute(con, \"SET SHOWPLAN_TEXT ON\", immediate = TRUE)\ndbGetQuery(con, \"SELECT * FROM #temp WHERE a &gt; 0\")\ndbExecute(con, \"SET SHOWPLAN_TEXT OFF\", immediate = TRUE)"
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#connector-objects",
    "href": "blog/posts/dbi-3-2.html#connector-objects",
    "title": "Maintaining DBI, 2/4",
    "section": "Connector objects",
    "text": "Connector objects\nThe existing method in DBI has been to create the driver object and then call dbConnect() with the connection arguments. However there are times when a user may need to do the following:\n\nSeparate connection arguments from establishing a connection\nSerialize the connector to file in order to establish the same connection later\nMaintain multiple connectors in a list for testing different DBMS\n\nIn order to address these use cases, users now have the ability to create a “connector object” that combines the driver and connection arguments, allowing the user to call dbConnect() without additional arguments. This feature is implemented in {DBI}, and works out of the box for all DBI backends.\n\nExample\nlibrary(DBI)\n\n# Old way:\ndrv &lt;- RSQLite::SQLite()\ncon &lt;- dbConnect(drv, dbname = \":memory:\")\ndbDisconnect(con)\n\n# New connector object:\ncnr &lt;- new(\"DBIConnector\",\n  .drv = RSQLite::SQLite(),\n  .conn_args = list(dbname = \":memory:\")\n)\ncnr\n\n## &lt;DBIConnector&gt;&lt;SQLiteDriver&gt;\n## Arguments:\n## $dbname\n## [1] \":memory:\"\n\ncon &lt;- dbConnect(cnr)\ndbDisconnect(con)\nIn addition, arguments can be functions, a useful feature for passwords and other sensitive connection data."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#logging-with-the-dblog-package",
    "href": "blog/posts/dbi-3-2.html#logging-with-the-dblog-package",
    "title": "Maintaining DBI, 2/4",
    "section": "Logging with the {dblog} package",
    "text": "Logging with the {dblog} package\nWhen using applications in production, keeping logs is an invaluable part of a sound infrastructure. The new {dblog} package is designed to be as simple as possible. It can be used as a standalone package or in conjunction with packages like {dbplyr}.\n{dblog} helps both with troubleshooting as well as auditing the queries that that are used to access a database. Similar to Perl’s DBI::log, the goal of {dblog} is to implement logging for arbitrary DBI backends.\n{dblog} is straightforward in its use. Start by initializing a logging driver using dblog() prior to connecting to a database management system. All calls to DBI methods are logged and by default printed to the console (or redirected to a file). The entirety of the logging output is runnable R code, so users can copy, paste, and execute the logging code for debugging.\n\nUsing dblog() to connect to SQLite\nlibrary(dblog)\n\ndrv &lt;- dblog(RSQLite::SQLite())\n#&gt; drv1 &lt;- RSQLite::SQLite()\n\n\nAll calls to DBI methods are logged, by default to the console\nconn &lt;- dbConnect(drv, file = \":memory:\")\n#&gt; conn1 &lt;- dbConnect(drv1, file = \":memory:\")\n\ndbWriteTable(conn, \"iris\", iris[1:3, ])\n#&gt; dbWriteTable(conn1, name = \"iris\", value = structure(list(Sepal.Length = c(5.1, 4.9, \n#&gt; 4.7), Sepal.Width = c(3.5, 3, 3.2), Petal.Length = c(1.4, 1.4, 1.3), Petal.Width = c(0.2, \n#&gt; 0.2, 0.2), Species = structure(c(1L, 1L, 1L), .Label = c(\"setosa\", \"versicolor\", \n#&gt; \"virginica\"), class = \"factor\")), row.names = c(NA, 3L), class = \"data.frame\"), overwrite = FALSE, \n#&gt;     append = FALSE)\n\ndata &lt;- dbGetQuery(conn, \"SELECT * FROM iris\")\n#&gt; dbGetQuery(conn1, \"SELECT * FROM iris\")\n#&gt; ##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; ## 1          5.1         3.5          1.4         0.2  setosa\n#&gt; ## 2          4.9         3.0          1.4         0.2  setosa\n#&gt; ## 3          4.7         3.2          1.3         0.2  setosa\n\ndbDisconnect(conn)\n#&gt; dbDisconnect(conn1)\n\ndata\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 2          4.9         3.0          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\nThis also works in scenarios where DBI is used under the hood by other packages like dbplyr or tidypredict. The log will represent the DBI operations issued, which allows for a better understanding of the internals."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#testing-your-infrastructure-for-dbi-compatibility",
    "href": "blog/posts/dbi-3-2.html#testing-your-infrastructure-for-dbi-compatibility",
    "title": "Maintaining DBI, 2/4",
    "section": "Testing your infrastructure for DBI compatibility",
    "text": "Testing your infrastructure for DBI compatibility\nDBItest (on CRAN in version 1.7.0) is currently geared towards usage as part of a package’s test suite. With some effort it is possible to test a database backend against a custom database. This can help verify that your database installation gives expected results when accessed with DBI with specific connection arguments. The DBItest article contains a new section that describes how to achieve this, including a primer on using {dblog} to understand the cause of test failures."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#a-list-of-dbi-backends",
    "href": "blog/posts/dbi-3-2.html#a-list-of-dbi-backends",
    "title": "Maintaining DBI, 2/4",
    "section": "A list of DBI backends",
    "text": "A list of DBI backends\nThe new backends repository lists all known DBI backends, as retrieved via a code search on GitHub. The list is available in the README, and as a static web API for programmatic processing."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#better-handling-of-time-zones",
    "href": "blog/posts/dbi-3-2.html#better-handling-of-time-zones",
    "title": "Maintaining DBI, 2/4",
    "section": "Better handling of time zones",
    "text": "Better handling of time zones\nTime zones are used to convert between absolute time and civil time, where absolute time exists independent of human-created measures such as calendars, days, and dates, whereas civil time is comprised of years, months, days, hours, minutes, and seconds. For a more in-depth reading on absolute time, civil time, and time zones, please read this excerpt from the ODBC README.\nFor programming and data analysis, accurate handling time zones is crucial. {odbc} has set an example for how to handle time zones through the inclusion of timezone and timezone_out arguments to dbConnect(). The timezone argument controls the server time zone, which may be different from UTC. The timezone_out argument specifies the time zone to use for displaying times.\nThis strategy gives the user control over datetime information passed on to and retrieved from the database. Both arguments in combination should be able to support a broad variety of use cases and server setups. {RMariaDB} and {RPostgres} will incorporate this strategy with their next CRAN release. {RPostgres} already has gained a timezone argument in its dbConnect() method."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#window-function-support-in-rsqlite",
    "href": "blog/posts/dbi-3-2.html#window-function-support-in-rsqlite",
    "title": "Maintaining DBI, 2/4",
    "section": "Window function support in {RSQLite}",
    "text": "Window function support in {RSQLite}\nRSQLite 2.1.4 and later includes sqlite &gt;= 3.29.0, which introduces support for window functions.\nlibrary(tidyverse)\nlibrary(dbplyr)\n\ntbl &lt;- memdb_frame(a = rep(1:2, 5), b = 1:10)\n\ntbl %&gt;% \n  group_by(a) %&gt;%\n  window_order(b) %&gt;% \n  mutate(c = cumsum(b)) %&gt;% \n  ungroup()\n\n## # Source:     lazy query [?? x 3]\n## # Database:   sqlite 3.30.1 [:memory:]\n## # Ordered by: b\n##        a     b     c\n##    &lt;int&gt; &lt;int&gt; &lt;int&gt;\n##  1     1     1     1\n##  2     1     3     4\n##  3     1     5     9\n##  4     1     7    16\n##  5     1     9    25\n##  6     2     2     2\n##  7     2     4     6\n##  8     2     6    12\n##  9     2     8    20\n## 10     2    10    30"
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#cii-best-practices-badges-for-all-repos",
    "href": "blog/posts/dbi-3-2.html#cii-best-practices-badges-for-all-repos",
    "title": "Maintaining DBI, 2/4",
    "section": "CII “best practices” badges for all repos",
    "text": "CII “best practices” badges for all repos\nCII “best practices” have been implemented for {DBItest}, {RMariaDB}, {RPostgres} and {RSQLite}. The {DBItest} repository has a brand-new badge, the badges for the other repositories will follow suit."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#package-updates",
    "href": "blog/posts/dbi-3-2.html#package-updates",
    "title": "Maintaining DBI, 2/4",
    "section": "Package updates",
    "text": "Package updates\nThe following package versions were sent to CRAN in conjunction with this blog post:\n\nDBI 1.1.0 (NEWS)\nDBItest 1.7.0 (NEWS)\nRMariaDB 1.0.8 (NEWS)\nRPostgres 1.2.0 (NEWS)\nRSQLite 2.1.5 (NEWS)\n\nBefore that, minor updates of the database backend packages were necessary to comply with stricter CRAN checks and toolchain updates."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#future-work",
    "href": "blog/posts/dbi-3-2.html#future-work",
    "title": "Maintaining DBI, 2/4",
    "section": "Future work",
    "text": "Future work\nThe remainder of the blog post discusses future directions for DBI and the backend packages.\n\nDBI tutorials\nImproving documentation is a priority. DBI is still lacking an up-to-date tutorial with a low entry bar that helps users connect to their database and execute queries. The updated README is a little step forward, but a slightly more comprehensive versions with link to more detailed information would be helpful.\n\n\nTerraforming databases\nNow that using DBItest to test backends against custom infrastructure is understood, it becomes easier to enhance tests so that not only pristine setups are tested, but also databases with nonstandard settings for time zone, character encoding or collation. Terraform helps automating the setup of databases of different flavors on cloud providers such as Azure or Google Cloud. The desired state of computing infrastructure is specified in a declarative way. This allows testing a much broader variety of databases and configurations, without maintaining expensive infrastructure: databases can be spun up when needed and torn down when done.\nIt would be helpful to have a selection of open-source and commercial databases in different configuration settings ready for testing.\n\n\nQuery cancellation\nCurrently, {odbc} and many other backends freeze while a query is executed. It is easy to underestimate the runtime of a query, or to accidentally execute a query that is running too long. This severely hampers interactive workflows: a frozen R session means forcibly restarting R, or worse, the development environment.\nMateusz Żółtak has contributed a pull request that implements support for graceful query cancellation in {RPostgres}. Initial research suggests that for {odbc} it may be possible to implement this in a similar fashion. It remains to be seen if an implementation is viable, and if the database libraries used by {RMariaDB} and {RSQLite} support this mode of operation."
  },
  {
    "objectID": "blog/posts/dbi-3-2.html#acknowledgments",
    "href": "blog/posts/dbi-3-2.html#acknowledgments",
    "title": "Maintaining DBI, 2/4",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI’d like to thank Katharina Brunner and Jesse Mostipak for help with composing this blog post."
  },
  {
    "objectID": "blog/posts/dbi-3-3.html",
    "href": "blog/posts/dbi-3-3.html",
    "title": "Maintaining DBI, 3/4",
    "section": "",
    "text": "DBI stands for database interface. The DBI package connects R to database management systems (DBMS). The goal of DBI is to provide a common interface for database access, regardless of the specific underlying DBMS. DBI works with a variety of DBMS, such as Postgres, MariaDB, and SQLite, through dedicated backend packages. For first-time users I recommend starting with the new introductory tutorial.\nThe current version of DBI is 1.1.1. This blog post attempts to define the scope of the DBI project, summarizes recent developments in DBI and related packages, and showcases future work."
  },
  {
    "objectID": "blog/posts/dbi-3-3.html#what-is-dbi",
    "href": "blog/posts/dbi-3-3.html#what-is-dbi",
    "title": "Maintaining DBI, 3/4",
    "section": "",
    "text": "DBI stands for database interface. The DBI package connects R to database management systems (DBMS). The goal of DBI is to provide a common interface for database access, regardless of the specific underlying DBMS. DBI works with a variety of DBMS, such as Postgres, MariaDB, and SQLite, through dedicated backend packages. For first-time users I recommend starting with the new introductory tutorial.\nThe current version of DBI is 1.1.1. This blog post attempts to define the scope of the DBI project, summarizes recent developments in DBI and related packages, and showcases future work."
  },
  {
    "objectID": "blog/posts/dbi-3-3.html#scope-of-the-dbi-project",
    "href": "blog/posts/dbi-3-3.html#scope-of-the-dbi-project",
    "title": "Maintaining DBI, 3/4",
    "section": "Scope of the DBI project",
    "text": "Scope of the DBI project\nThe DBI package is perfect for anyone looking to connect to a database, read/write entire tables, and/or execute SQL queries. DBI gives a direct access to the database driver, leaving more sophisticated data query and manipulation tasks to packages like dbplyr, dbx and rquery.\nThe core DBI project in R provides an interface for databases, specified in textual form and via automated tests. The DBI specification contains a detailed description of the methods provided by DBI. In summary, the interface covers:\n\nDiscovery of tables, also in schemas\nReading/writing/creating/removing tables\nExecuting queries, fetching data (with parameters)\nSafe quoting: low-level composition of queries\nTransactions\n\nDBI should provide a way to ingest data of any type into R, at least in serialized form (e.g. string or blob). It should offer a robust reliable interface for dependent packages; anything beyond this scope should be left to packages that extend DBI:\n\narkdb: archival of database data\nconnection: integrate database connections with the RStudio IDE\ndbplyr and rquery: generation of SQL queries\ndbx: DBI extension for data manipulation\ndittodb: mocking for databases\ndm: relational data models (via dbplyr)\npool: connection pooling\nsqlr: schema definition\n\nand many more."
  },
  {
    "objectID": "blog/posts/dbi-3-3.html#recent-developments-in-dbi",
    "href": "blog/posts/dbi-3-3.html#recent-developments-in-dbi",
    "title": "Maintaining DBI, 3/4",
    "section": "Recent developments in DBI",
    "text": "Recent developments in DBI\nThis section discusses:\n\nthe new DBI tutorials,\nimprovements for datetime data,\nother notable changes,\nthe move to GitHub Actions.\n\nThe first three items directly affect DBI users, the last item much less so. It is nevertheless an important investment in the stability of the DBI infrastructure.\n\nNew tutorials\nJames Wondrasek substantially expanded the “Introduction to DBI” article and added a second article. DBI now features two tutorials. The introduction includes a walkthrough that describes connecting and querying a real database. The “Advanced DBI usage” tutorial shows more advanced examples of quoting and parameter binding. The tutorials are an important first-hand resource for new users.\n\n\nTime zones\nTo date, it was only possible to work reliably with time zones when the database connection represented all times in UTC. This poses a few problems in practice:\n\nNot all databases store timestamps as UTC or with time zone offset, often local time is assumed by the data model.\nOther systems often use the default setting for time zone, this harms interoperability of DBI in these cases.\nConversion of timestamps to dates via the SQL function DATE is only correct when the session time zone is set correctly.\n\nRMariaDB 1.1.0 and RPostgres 1.3.0 gained more robust support for datetime values. As proposed in the previous blog post, new arguments timezone and timezone_out were added. Both arguments should use Olson names such as Europe/Berlin or America/New_York, not time offsets like +01:00; the latter may change with daylight time savings season. If timezone is set to NULL, an attempt is made to detect the correct time zone on the database. Thanks to Philipp Schauberger for contributing the initial timezone argument for RMariaDB.\nRSQLite does not natively support dates or times. A promising pull request is underway that implements support for treating numeric values as time offsets if the column type is declared in a specific way.\n\n\nNotable changes to DBI backends\nThe following package versions were sent to CRAN since the last blog post:\n\nDBI 1.1.0 -&gt; 1.1.1 (NEWS)\nRMariaDB 1.0.8 -&gt; 1.1.0 (NEWS)\nRPostgres 1.2.0 -&gt; 1.3.1 (NEWS)\nRSQLite 2.1.5 -&gt; 2.2.2 (NEWS)\n\nHighlights are:\n\nDBI: Two new tutorials; minor improvements to dbQuoteLiteral(), this is relevant for backends that don’t provide their own implementation.\nRMariaDB: Better handling of data types and character encoding; minor tweaks to dbBind() and dbQuoteLiteral().\nRPostgres: The new Redshift() driver that allows downstream packages to distinguish between Postgres and Amazon RedShift (thanks Hadley Wickham); minor improvements for querying and passing date and time types, postgresWaitForNotify() contributed by Jamie Lentin.\nRSQLite: dbAppendTable() is faster, strings and blobs can have virtually unlimited size (limit 2 GB), embedded SQLite library is now in version 3.34.\nDBItest: understanding which tests failed is now simpler, also thanks to simpler backtraces; test_some() integrates with the dblog package and shows DBI methods called; established compatibility with testthat 3.0.0; better and more robust tests.\nRKazam: Is now a template repository\n\nThanks to Jeroen Ooms for maintaining Windows versions for the database libraries.\n\n\nQA and automation\nAutomated tests are a crucial part of modern software engineering. These are often augmented with continuous integration (CI) services that run these tests regularly or with every change to the code. When I started working on DBI, Travis CI offered excellent continuous integration services for open-source repositories. Unfortunately, this is no longer the case: the free tier introduced a limit on CI build time, rendering it effectively unusable for DBI.\nGitHub Actions is a CI/CD platform tightly integrated with GitHub. It is somewhat simpler to set up, also for creating workflows that e.g. open a pull request. It is sufficient to add a YAML configuration file to a dedicated location in the repository. Each build automatically obtains a token that can be used to interact with the GitHub API. R support is provided by dedicated workflows and actions contributed by RStudio. Check status is conveniently reported in detail with each pull request, and the checks run considerably faster due to higher concurrency.\nContinuous integration for all packages in the project has moved to GitHub Actions. Cross-platform checks for all backends on the major operating systems were a bit challenging, because the tests require a live database. Thanks to Andrew Kane for providing GitHub actions that install database engines on all platforms, this greatly simplified the move.\nThree more parts of the infrastructure were updated as part of the move:\n\nThe odbc and duckdb packages are now also checked when the DBItest package updates. This ensures that new or amended specifications do not break these packages. If you maintain a DBI backend that uses DBItest, get in touch for integrating your backend with these checks.\nThe list of DBI backends is now continuously updated. Updates to backends are applied automatically. Every time a new backend is found, a pull request is opened.\nA new pull request is opened in RSQLite when a new version of the SQLite library is available. This makes it much easier to keep the bundled SQLite version up to date."
  },
  {
    "objectID": "blog/posts/dbi-3-3.html#future-work",
    "href": "blog/posts/dbi-3-3.html#future-work",
    "title": "Maintaining DBI, 3/4",
    "section": "Future work",
    "text": "Future work\nThe last blog post already identified major milestones:\n\nquery cancellation\ntesting on remote databases\n\nA triage of the contributed issues has identified the following additional major topics:\n\nimmediate argument to dbSendQuery() and dbSendStatement() for RMariaDB and RPostgres\nperformance of table import\nreconnect if a database connection is lost\n\nOther minor issues include:\n\nSSL connections\nauthentication plugins\nsupport for more data types: arrays, JSON, …\n\nI’m planning to resolve most of the remaining issues in a final sprint. Some of these issues can be outsourced to other packages, according to the scope outlined in the previous sections, priority should be given to issues that must be resolved in the core packages. Future work might shift towards providing or improving useful extensions."
  },
  {
    "objectID": "blog/posts/dbi-3-3.html#acknowledgments",
    "href": "blog/posts/dbi-3-3.html#acknowledgments",
    "title": "Maintaining DBI, 3/4",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI’d like to thank James Wondrasek for creating the DBI tutorials and for a review of this blog post, Angelica Becerra for reviewing the material, and the numerous contributors to the packages in the “Maintaining DBI” project (DBI¹, RSQLite², RPostgres³, RMariaDB⁴, and DBItest⁵):\n@abalter³, @alanpaulkwan², @AllenSuttonValocity³, @altay-oz³, @anderic1², @andybeet¹, @arencambre⁴, @artemklevtsov³, @bastianilso⁴, @bczernecki¹, @Byggvir⁴, @Chrisjb¹, @clementbfeyt⁴, @colearendt¹, @daattali¹, @datawookie¹, @dpprdan³⁵, @elfatherbrown⁴, @EntwicklR², @ericemc3⁴, @formix³, @fproske¹, @georgevbsantiago¹, @GitHunter0¹, @hadley²³, @hmeleiro¹, @hpages², @imlijunda³, @inferiorhumanorgans³, @jarauh⁴, @jawond¹, @jeroen³, @jimhester¹, @jjesusfilho³, @jsilve24², @kforner⁴, @kmishra9², @Kodiologist¹², @LaugeGregers³, @luispuerto², @martinstuder⁵, @matteodelucchi⁴, @MaximumV¹, @mbannert³, @mbedward³, @mgirlich², @mlamias¹, @mllg¹, @mmuurr³, @momeara³, @MonteShaffer⁴, @Mosk915⁴, @nfultz², @norquanttech³, @OMalytics³, @oriolcmp⁴, @Osc2wall⁴, @psychobas², @randyzwitch⁵, @rcfree², @rnorberg¹, @rodriguesk², @rossholmberg⁴, @Sahil308⁴, @samuel-cs4⁴, @schuemie², @shutinet², @splaisan², @Trowic⁴, @verajosemanuel⁴, @VictorYammouni¹, @vigyoyo⁴, @vikram-rawat³, @vspinu³, @warnes³, @wiligl², @ycphs⁴, and @zyxdef¹."
  },
  {
    "objectID": "blog/posts/dbi-1-halfway.html",
    "href": "blog/posts/dbi-1-halfway.html",
    "title": "Halfway through “Improving DBI”",
    "section": "",
    "text": "In early 2016 the R Consortium partially accepted my “Improving DBI” proposal. An important part is the design and implementation of a testable DBI specification. Initially I also proposed to make three DBI backends to open-source databases engines (RSQLite, RMySQL, and RPostgres) compatible to the new DBI specification, but funding allows to work on only one DBI backend. I chose RSQLite for a number of reasons:\nThe project has reached an important milestone, with the release of RSQLite 1.1. This post reports the progress achieved so far, and outlines the next steps."
  },
  {
    "objectID": "blog/posts/dbi-1-halfway.html#rsqlite",
    "href": "blog/posts/dbi-1-halfway.html#rsqlite",
    "title": "Halfway through “Improving DBI”",
    "section": "RSQLite",
    "text": "RSQLite\nWhile the RSQLite API has changed very little (hence the minor version update), it includes a complete rewrite of the original 1.0.0 sources in C++. This has considerably simplified the code, which makes future maintenance easier, and allows us to take advantage of the more sophisticated memory management tools available in Rcpp, which help protect against memory leaks and crashes.\nRSQLite 1.1 brings a number of improvements:\n\nNew strategy for prepared queries: Create a prepared query with dbSendQuery() or dbSendStatement() and bind values with dbBind(). This allows you to efficiently re-execute the same query/statement with different parameter values iteratively (by calling dbBind() several times) or in a batch (by calling dbBind() once with a data-frame-like object).\nSupport for inline parametrised queries via the param argument to dbSendQuery(), dbGetQuery(), dbSendStatement() and dbExecute(), to protect from SQL injection.\nThe existing methods dbSendPreparedQuery() and dbGetPreparedQuery() have been soft-deprecated, because the new API is more versatile, more consistent and stricter about parameter validation.\nUsing UTF8 for queries and parameters: this mean that non-English data should just work without any additional intervention.\nImproved mapping between SQLite’s cell-types and R’s column-types.\n\nSee the release notes for further changes.\nThe rewrite was implemented by Hadley Wickham before the “Improving DBI” project started, and has been available for a long time on GitHub. Nevertheless, the CRAN release has proven much more challenging than anticipated, because so many CRAN and Bioconductor packages import it. (Maintainers of reverse dependencies might remember multiple e-mails where I was threatening to release RSQLite “for real”.) My aim was to break as little existing code as possible. After numerous rounds of revdep-checking and improving RSQLite, I’m proud to report that the vast majority of reverse dependencies pass their checks just as well (and as quickly!) as they did with v1.0.0. Most tests from v1.0.0 are still present in the current codebase. This means that non-packaged code also has a good chance to work unchanged. I’m happy to work with package maintainers or users whose code breaks after the update.\nDBI\n\nI have also released several DBI updates to CRAN, mostly to introduce new generics such as dbBind() (for parametrized/prepared queries) or dbSendStatement() and dbExecute() (for statements which don’t return data). The definition of a formal DBI specification is part of the project, a formatted version is updated continuously."
  },
  {
    "objectID": "blog/posts/dbi-1-halfway.html#dbitest",
    "href": "blog/posts/dbi-1-halfway.html#dbitest",
    "title": "Halfway through “Improving DBI”",
    "section": "DBItest",
    "text": "DBItest\nIn addition to the textual specification in the DBI package, the DBItest package provides backend independent tests for DBI packages. It can be easily used by package authors to ensure that they follow the DBI specification. This is important because it allows you to take code that works with one DBI backend and easily switch to a different backend (providing that they both support the same SQL dialect). Literate programming techniques using advanced features of roxygen2 help keeping both code and textual specifications in close proximity, so that amendments to the text can be easily tracked back to changes of the test code, and vice versa."
  },
  {
    "objectID": "blog/posts/dbi-1-halfway.html#next-steps",
    "href": "blog/posts/dbi-1-halfway.html#next-steps",
    "title": "Halfway through “Improving DBI”",
    "section": "Next steps",
    "text": "Next steps\nThe rest of the project will focus on finalizing the specification in both code and text (mostly discussed on GitHub in the issue trackers for the DBI and DBItest projects). At least one new helper package (to handle 64-bit integer types) will be created, and DBI, DBItest, and RSQLite will see yet another release: The first two will finalize the DBI specification, and RSQLite will fully conform to it.\nThe development happens entirely on GitHub in repositories of the rstats-db organization. Feel free to try out development versions of the packages found there, and to report any problems or ideas at the issue trackers."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DBI for R",
    "section": "",
    "text": "R’s interface to databases, with a testable and human-readable specification, a selection of backend packages to connect with various databases, and a boilerplate for developing new backends.\n \n  \n   \n  \n    \n     GitHub"
  },
  {
    "objectID": "index.html#packages",
    "href": "index.html#packages",
    "title": "DBI for R",
    "section": "Packages",
    "text": "Packages\n\n\nInterface\nThe DBI package defines generic methods that work almost identically across databases. This is checked by DBItest, which also provides a human-readable specification.\n\n\nBackends\nThe RSQLite, MariaDB, and RPostgres packages implement methods defined by DBI that connect to specific databases. There are more packages that connect to other databases.\n\n\nBoilerplate\nThe RKazam package makes it easy for package developers to create a new package to a new DBMS."
  },
  {
    "objectID": "index.html#blog-posts",
    "href": "index.html#blog-posts",
    "title": "DBI for R",
    "section": "Blog posts",
    "text": "Blog posts\n\n\n\n\n\n\nMaintaining DBI, 4/4\n\n\n\n\n\nSummarizing the progress of 2021\n\n\n\n\n\n\nDec 21, 2021\n\n\nKirill Müller\n\n\n\n\n\n\n\n\nMaintaining DBI, 3/4\n\n\n\n\n\nSummarizing the progress of 2020\n\n\n\n\n\n\nJan 20, 2021\n\n\nKirill Müller\n\n\n\n\n\n\n\n\nMaintaining DBI, 2/4\n\n\n\n\n\nSummarizing the progress of 2019\n\n\n\n\n\n\nDec 19, 2019\n\n\nKirill Müller\n\n\n\n\n\n\n\n\nMaintaining DBI, 1/4\n\n\n\n\n\nSummarizing the progress of 2018\n\n\n\n\n\n\nDec 31, 2018\n\n\nKirill Müller\n\n\n\n\n\n\n\n\nDone “Establishing DBI”!?\n\n\n\n\n\nSummary of the “Establishing DBI” project\n\n\n\n\n\n\nMay 1, 2018\n\n\nKirill Müller\n\n\n\n\n\n\n\n\nConnecting to open source databases\n\n\n\n\n\nPresentation at rstudio::conf, San Diego\n\n\n\n\n\n\nFeb 2, 2018\n\n\nKirill Müller\n\n\n\n\n\n\n\n\nDBItest: Specification\n\n\n\n\n\nSummary of the “Improving DBI” project\n\n\n\n\n\n\nMay 15, 2017\n\n\nKirill Müller\n\n\n\n\n\n\n\n\nHalfway through “Improving DBI”\n\n\n\n\n\nIntermediate status report on the “Improving DBI” project\n\n\n\n\n\n\nDec 6, 2016\n\n\nKirill Müller\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "R-DBI blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nMaintaining DBI, 4/4\n\n\n\n\n\nSummarizing the progress of 2021\n\n\n\n\n\n\n21 December 2021\n\n\nKirill Müller\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\nMaintaining DBI, 3/4\n\n\n\n\n\nSummarizing the progress of 2020\n\n\n\n\n\n\n20 January 2021\n\n\nKirill Müller\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nMaintaining DBI, 2/4\n\n\n\n\n\nSummarizing the progress of 2019\n\n\n\n\n\n\n19 December 2019\n\n\nKirill Müller\n\n\n12 min\n\n\n\n\n\n\n  \n\n\n\n\nMaintaining DBI, 1/4\n\n\n\n\n\nSummarizing the progress of 2018\n\n\n\n\n\n\n31 December 2018\n\n\nKirill Müller\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\nDone “Establishing DBI”!?\n\n\n\n\n\nSummary of the “Establishing DBI” project\n\n\n\n\n\n\n01 May 2018\n\n\nKirill Müller\n\n\n15 min\n\n\n\n\n\n\n  \n\n\n\n\nConnecting to open source databases\n\n\n\n\n\nPresentation at rstudio::conf, San Diego\n\n\n\n\n\n\n02 February 2018\n\n\nKirill Müller\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nDBItest: Specification\n\n\n\n\n\nSummary of the “Improving DBI” project\n\n\n\n\n\n\n15 May 2017\n\n\nKirill Müller\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nHalfway through “Improving DBI”\n\n\n\n\n\nIntermediate status report on the “Improving DBI” project\n\n\n\n\n\n\n06 December 2016\n\n\nKirill Müller\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/dbi-3-1.html",
    "href": "blog/posts/dbi-3-1.html",
    "title": "Maintaining DBI, 1/4",
    "section": "",
    "text": "Much earlier this year my proposal for the third R Consortium project for working on DBI has been accepted. DBI is a set of virtual functions declared in the DBI package. Communication with the database is implemented by DBI backends, packages that import DBI and implement its methods. A common interface is helpful for both users and backend implementers. Users, including package developers for DBMS-agnostic packages, need to memoize only one set of functions. Backend developers can focus on functionality instead of design decisions, and can benefit from a large base of potential users right from the start.\nI’m grateful for the trust, and will do my best to make the “Maintaining DBI” project a success. For this round, the main goals are: maintain, enhance, disseminate. The project is delayed mostly becase I grossly underestimated how much time and energy it would take to set up cynkra. The new joint venture with Christoph Sax consults businesses and organizations on matters related to R, statistics, data, and software. We are strongly committed to R and open-source software, and more priority will be given the “Maintaining DBI” project next year.\nThis blog post, much later than planned, summarizes the efforts of the past year: presentations at meetups, the “Core Infrastructure Initiative” badge, and activity in the various repositories of the r-dbi GitHub organization. I’ll repeat the big picture issues from the proposal and present plans for future development."
  },
  {
    "objectID": "blog/posts/dbi-3-1.html#presentations-at-meetups",
    "href": "blog/posts/dbi-3-1.html#presentations-at-meetups",
    "title": "Maintaining DBI, 1/4",
    "section": "Presentations at meetups",
    "text": "Presentations at meetups\nI presented DBI at the Berlin R user group, at the amstRdays, and at the Zurich R meetup. The presentation in Berlin made me realize that a progress report isn’t that helpful for a general audience. The Zurich version of the presentation featured a DBI intro also suitable for new users, merely highlighting recent developments. These slides, and the intro at db.rstudio.com seem to be the most recent general-purpose introduction materials available. I think an entry-level tutorial would be a good fit for a DBI vignette."
  },
  {
    "objectID": "blog/posts/dbi-3-1.html#cii-badge",
    "href": "blog/posts/dbi-3-1.html#cii-badge",
    "title": "Maintaining DBI, 1/4",
    "section": "CII badge",
    "text": "CII badge\nFrom https://bestpractices.coreinfrastructure.org/en:\n\nThe Linux Foundation (LF) Core Infrastructure Initiative (CII) Best Practices badge is a way for Free/Libre and Open Source Software (FLOSS) projects to show that they follow best practices. Projects can voluntarily self-certify, at no cost, by using this web application to explain how they follow each best practice. The CII Best Practices Badge is inspired by the many badges available to projects on GitHub. Consumers of the badge can quickly assess which FLOSS projects are following best practices and as a result are more likely to produce higher-quality secure software.\n\nThe CII badge can be obtained after a self-certification process that comprises ~70 soft and hard questions about the project around the following topics:\n\nBasics: Project URLs, license, documentation\nChange Control: Version control and version numbers\nReporting: Tracking issues and vulnerabilities\nQuality: Build and test system, best practices\nSecurity (software)\nAnalysis (static and dynamic)\n\nAfter completing the process, projects are entitled to wear a badge like the one below for the DBI project:\n\n\n\nOpenSSF Best Practices\n\n\nA click on the badge takes you to the detailed assessment. In addition to the badge, completing the self-certification allows the maintainer to rethink if workflows and practices can be improved.\nDBI is currently has the “passing” status, the backend packages and DBItest will follow. I have compiled the changes that were necessary to obtain that status below. It appears to be much more difficult but not impossible to obtain the “silver” status.\n\nNecessary changes to the DBI package\nSeveral files had to be added or updated:\n\nCONTRIBUTING.md: This file describes how to contribute to the project. A link to this file is available when you open a new issue. The function usethis::use_tidy_contributing() created the files which I tweaked a bit.\nLICENSE.md: The full license terms need to be available as part of the project. To create the file, I contributed usethis::use_lgpl_2.1_license(). Because CRAN discourages redistribution of copies of standard license texts in packages, the file has been added to .Rbuildignore. This makes the file available in the GitHub repository, but not package file on CRAN.\nREADME.md: Added missing installation instructions.\n\nThough not on the CII badge checklist, I also added:\n\nISSUE_TEMPLATE.md: pre-populates the issue description when opening a new issue. This is a tweaked version of the file provided by usethis::use_tidy_issue_template().\nCODE_OF_CONDUCT.md: The default file as added by usethis::use_code_of_conduct().\n\nOne badge still had an HTTP image source, after changing it to HTTPS the criterion that the website needs to use TLS was satisfied.\nEstablishing a process for reporting code vulnerabilities was perhaps the most challenging part. It seems unclear if it applies to R packages at all, in particular to an interface-only package such as DBI. The solution was to add a link with text to the project page https://dbi.r-dbi.org, asking to send an e-mail and await further instructions."
  },
  {
    "objectID": "blog/posts/dbi-3-1.html#future-development",
    "href": "blog/posts/dbi-3-1.html#future-development",
    "title": "Maintaining DBI, 1/4",
    "section": "Future development",
    "text": "Future development\nThe principal roadmap for future development has been outlined in the project proposal. There are both “hard” and “soft” issues to solve, repeated below, with comments based on experience from the past year.\n\n“Hard” issues\n\nThe test suite for the DBI specificaton in DBItest is currently designed to run as part of the package checks. The next step is to support running the test suite against a particular R + DBMS installation, to ensure that code interoperating with that DBMS in that environment runs as expected.\n\nShouldn’t be too hard, but need to keep the second “soft” issue in mind.\n\nUsers expect the hard disk or the DBMS to be the limiting factor for loading data, but DBI still lacks a consistent interface for fast data import.\n\nThe new arkdb package offers a dedicated interface for importing data, I still think this functionality should better live there (or elsewhere).\n\nThe syntax for query placeholders currently depends on the DBMS. A consistent interface would be useful, in particular for implementers of packages that compute on the database.\n\nThis has already caused some confusion. Shouldn’t be too hard either, but requires a compatibility mode so that existing code doesn’t break.\n\nThe RPostgres package now has special handling for geometry data. A generic extension to arbitrary data types via hooks would allow e.g. returning JSON data directly as a \"json\" class without user-initiated manual conversion.\n\nThis seems to be a bigger problem, requiring some thought and design.\n\n\n\n\n“Soft” issues\n\nSome users reported installation problems on specific architectures, or connectivity problems with certain databases, or other specific issues. Making the new backends accessible for various combinations of OS/hardware, software, and configuration, will help the adoption of the new packages.\n\nI remember seeing many SSL and timezone issues, as well as genuine bugs like the representation of times before 1970 on Windows. Expect some progress for the second blog post.\n\nThe internal architecture of the DBI specification in DBItest requires a bit of reworking. Currently, it is difficult to understand a test failure without inspecting the source code of DBItest. It is difficult to locate the source of a failure in the specification and in the code. Ideally, each test failure would come with a precise link to the part of the specification that is violated, and with a simple sequence of DBI method calls that allow replicating the failure externally.\n\nThat code I wrote 1-2 years ago requires some attention…\n\nThe communication related to the projects has been rather terse so far. The new website https://r-dbi.org can host blog posts highlighting different aspects of DBI, and serve as a resource for advice on connecting R with databases and computing on the database. This includes coordination and support for developments around DBI like sqlr, an interface for data definition statements on top of DBI.\n\nTogether with the new Databases CRAN Task View maintained by Yuan (Terry) Tang and https://db.rstudio.com/, the https://r-dbi.org should become a viable resource for new and experienced users alike. New users should be directed to tutorials and introductory material, whereas experienced users should expect to find pointers to solve the most common problems. The role of each of these websites remains to be shaped, some overlap may be desired.\n\nAll operations on DBI currently block until a result is available or the DBMS has indicated completion. Asynchronous operations allow parallel processing of multiple queries or statements, however some research is necessary to understand to what extent this can be supported realistically in DBI and for the existing backends.\n\nAdditional arguments to dbConnect(), like the new check_interrupts argument contributed to RPostgres by Mateusz Żółtak, are an option to experiment with asynchronous processing without disrupting existing code.\n\n\nThese lists are not comprehensive, new issues may surface over time, or the importance of issues mentioned above may fade."
  },
  {
    "objectID": "blog/posts/dbi-3-1.html#outlook-next-blog-post",
    "href": "blog/posts/dbi-3-1.html#outlook-next-blog-post",
    "title": "Maintaining DBI, 1/4",
    "section": "Outlook: next blog post",
    "text": "Outlook: next blog post\nThe “Maintaining DBI” project is driven by blog posts. I promised four blog posts, describing the ongoing maintenance and development. Each blog post will get a corresponding GitHub project, like the project for this and for the next blog post.\nFor the next iteration, I plan to improve documentation, do a release round for all packages, furnish more packages with a CII badge, review several new packages that build on top of DBI, and improve my responsiveness.\nA Walkthrough for first-time DBI users seems to be the highest priority, perhaps accompanied by an online course. Other documentation improvements mostly will address https://r-dbi.org.\nThe following is an excerpt of changes in the forthcoming CRAN releases of the DBI packages:\n\nRSQLite: window functions!\nRMariaDB: better handling for time zones\nDBItest: minor improvements\n\nNew packages worth reviewing include:\n\narkdb: Consistent (and fast?) import and export\nflobr: Converting files to blobs and back\nsqlr: SQLAlchemy-like DSL for data definition, work in progress\ndbplot: Plotting from the database\nand many others.\n\nAdding CII badges for the backend packages and DBItest will give a more consistent appearance of the entire project.\nAs a New Year’s resolution, I pledge to do a better job as package maintainer for DBI and related packages. I reserved a few hours each Monday to respond to issues raised on GitHub and other channels (SO, RStudio Community, Twitter, and the somewhat underappreciated R-SIG-DB mailing list). CI builds on Travis and AppVeyor also require occasional intervention. The remaining time will be spent on resolving known problems."
  },
  {
    "objectID": "blog/posts/dbi-3-1.html#acknowledgments",
    "href": "blog/posts/dbi-3-1.html#acknowledgments",
    "title": "Maintaining DBI, 1/4",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThanks to all contributors to DBI and the other projects in the r-dbi organization!\n\n\n\nDBI contributors"
  },
  {
    "objectID": "blog/posts/rstudio-conf.html",
    "href": "blog/posts/rstudio-conf.html",
    "title": "Connecting to open source databases",
    "section": "",
    "text": "Connecting to open source databases – RStudio"
  },
  {
    "objectID": "blog/posts/rstudio-conf.html#link-to-video",
    "href": "blog/posts/rstudio-conf.html#link-to-video",
    "title": "Connecting to open source databases",
    "section": "",
    "text": "Connecting to open source databases – RStudio"
  },
  {
    "objectID": "blog/posts/rstudio-conf.html#slides",
    "href": "blog/posts/rstudio-conf.html#slides",
    "title": "Connecting to open source databases",
    "section": "Slides",
    "text": "Slides\n\n\n\nFull screen version"
  },
  {
    "objectID": "blog/posts/dbi-2-final.html",
    "href": "blog/posts/dbi-2-final.html",
    "title": "Done “Establishing DBI”!?",
    "section": "",
    "text": "The “Establishing DBI” project, funded by the R consortium, started about a year ago. It includes the completion of two new backends, RPostgres and RMariaDB, and a quite a few interface extensions and specifications. Learn more about DBI, R’s database interface, on https://r-dbi.org.\nThis blog post showcases only the visible changes, a substantial amount of work went into extending the DBI specification and making the three open-source database backends compliant to it. After describing the release of the two new backends RMariaDB and RPostgres, I’ll be discussing the following improvements:\nI conclude with an outlook on things left to do."
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#release-of-rpostgres-and-rmariadb",
    "href": "blog/posts/dbi-2-final.html#release-of-rpostgres-and-rmariadb",
    "title": "Done “Establishing DBI”!?",
    "section": "Release of RPostgres and RMariaDB",
    "text": "Release of RPostgres and RMariaDB\nThe DBI specification has been formulated in the preceding R consortium project, “Improving DBI”. It is both an automated test suite and a human-readable description of behavior, implemented in the DBItest package. For this project, I extended this specification and could also use it to implement RPostgres and RMariaDB: for once, test-driven development was pure pleasure, because the tests were already there!\nI took over maintenance of the RPostgres and RMariaDB packages, which are complete rewrites of the RPostgreSQL and RMySQL packages, respectively. These packages use C++ (with Rcpp) as glue between R and the native database libraries. A reimplementation and release under a different name has made it much easier to fully conform to the DBI specification: only listing temporary tables and casting to blob or character is not supported by RMariaDB (due to a limitation of the DBMS), all other parts of the specification are fully covered.\nProjects that use RPostgreSQL or RMySQL can continue to do so, or switch to the new backends at their own pace (which likely requires some changes to the code). For new projects I recommend RPostgres or RMariaDB to take advantage of the thorougly tested codebases and of the consistency across backends."
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#schema-support",
    "href": "blog/posts/dbi-2-final.html#schema-support",
    "title": "Done “Establishing DBI”!?",
    "section": "Schema support",
    "text": "Schema support\nConsistent access of tables in database schemas was planned for the “Improving DBI” project already, but I have implemented it only recently. It felt safer to see how the interface works on three backends, as opposed to implementing it for just RSQLite and then perhaps having to adapt it.\nThe new Id() function constructs identifiers. All arguments must be named, yet DBI doesn’t specify the argument names, because DBMS have an inconsistent notion of namespaces. The objects returned by Id() are “dumb”, they gain meaning only when used in methods such as dbQuoteIdentifier() or dbWriteTable().\nFor listing database objects in schemas, the new dbListObjects() generic can be used. It returns a data frame that contains identifiers (like those created by the Id() function) and a flag that indicates if the identifier is complete (i.e., pointing to a table or view) or a prefix. Incomplete identifiers can be passed to dbListObjects() again, which allows traversing the tree of database objects.\nThe following example assumes a schema my_schema. A table named my_table is created in this schema, objects are listed, and the table is read again.\nlibrary(RPostgres)\npg_conn &lt;- dbConnect(Postgres())\n\ntable_name &lt;- Id(schema = \"my_schema\", table = \"my_table\")\ntable_name\n\n## &lt;Id&gt; schema = my_schema, table = my_table\n\ndata &lt;- data.frame(a = 1:3, b = letters[1:3])\ndbWriteTable(pg_conn, table_name, data)\n\ndbListObjects(pg_conn)\n\n##                               table is_prefix\n## 1    &lt;Id&gt; table = geography_columns     FALSE\n## 2     &lt;Id&gt; table = geometry_columns     FALSE\n## 3      &lt;Id&gt; table = spatial_ref_sys     FALSE\n## 4       &lt;Id&gt; table = raster_columns     FALSE\n## 5     &lt;Id&gt; table = raster_overviews     FALSE\n## 6             &lt;Id&gt; table = topology     FALSE\n## 7                &lt;Id&gt; table = layer     FALSE\n## 8                 &lt;Id&gt; table = temp     FALSE\n## 9            &lt;Id&gt; schema = topology      TRUE\n## 10          &lt;Id&gt; schema = my_schema      TRUE\n## 11 &lt;Id&gt; schema = information_schema      TRUE\n## 12         &lt;Id&gt; schema = pg_catalog      TRUE\n## 13             &lt;Id&gt; schema = public      TRUE\n\ndbListObjects(\n  pg_conn,\n  prefix = Id(schema = \"my_schema\")\n)\n\n##                                       table is_prefix\n## 1 &lt;Id&gt; schema = my_schema, table = my_table     FALSE\n\ndbReadTable(pg_conn, table_name)\n\n##   a b\n## 1 1 a\n## 2 2 b\n## 3 3 c\nIn addition to dbReadTable() and dbWriteTable(), also dbExistsTable() and dbRemoveTable() and the new dbCreateTable() and dbAppendTable() (see below) support an Id() object as table name. The dbQuoteIdentifier() method converts these objects to SQL strings. Some operations (e.g. checking if a table exists) require the inverse, the new dbUnquoteIdentifier() generic takes care of converting valid SQL identifiers to (a list of) Id() objects:\nquoted &lt;- dbQuoteIdentifier(pg_conn, table_name)\nquoted\n\n## &lt;SQL&gt; \"my_schema\".\"my_table\"\n\ndbUnquoteIdentifier(pg_conn, quoted)\n\n## [[1]]\n## &lt;Id&gt; schema = my_schema, table = my_table\nThe new methods work consistently across backends, only RSQLite is currently restricted to the default schema. (Schemas in RSQLite are created by attaching another database, this use case seemed rather exotic but can be supported with the new infrastructure.)"
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#quoting-literal-values",
    "href": "blog/posts/dbi-2-final.html#quoting-literal-values",
    "title": "Done “Establishing DBI”!?",
    "section": "Quoting literal values",
    "text": "Quoting literal values\nWhen working on the database backends, it has become apparent that quoting strings and identifiers isn’t quite enough. Now there is a way to quote arbitrary values, i.e. convert them to a string that can be pasted into an SQL query:\nlibrary(RSQLite)\nsqlite_conn &lt;- dbConnect(SQLite())\n\nlibrary(RMariaDB)\nmariadb_conn &lt;- dbConnect(MariaDB(), dbname = \"test\")\n\ndbQuoteLiteral(sqlite_conn, 1.5)\n\n## &lt;SQL&gt; 1.5\n\ndbQuoteLiteral(mariadb_conn, 1.5)\n\n## &lt;SQL&gt; 1.5\n\ndbQuoteLiteral(pg_conn, 1.5)\n\n## &lt;SQL&gt; 1.5::float8\n\ndbQuoteLiteral(mariadb_conn, Sys.time())\n\n## &lt;SQL&gt; '20180501204025'\n\ndbQuoteLiteral(pg_conn, Sys.time())\n\n## &lt;SQL&gt; '2018-05-01 22:40:25'::timestamp\nThe default implementation works for ANSI SQL compliant DBMS, the method for RPostgres takes advantage of the :: casting operator as seen in the examples."
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#more-fine-grained-creation-of-tables",
    "href": "blog/posts/dbi-2-final.html#more-fine-grained-creation-of-tables",
    "title": "Done “Establishing DBI”!?",
    "section": "More fine-grained creation of tables",
    "text": "More fine-grained creation of tables\nDBI supports storing data frames as tables in the database via dbWriteTable(). This operation consists of multiple steps:\n\nChecking if a table of this name exists, if yes:\n\nIf overwrite = TRUE, removing the table\nIf not, throwing an error\n\nCreating the table with the correct field structure\nPreparing the data for writing\nWriting the data\n\nTo reduce complexity and allow for more options without cluttering the argument list of dbWriteTable(), DBI now provides generics for the individual steps:\n\nThe existing dbRemoveTable() generic has been extended with temporary and fail_if_missing arguments. Setting temporary = TRUE makes sure that only temporaries are removed. By default, trying to remove a table that doesn’t exist fails, setting fail_if_missing = FALSE changes this behavior to a silent success.\nThe new dbCreateTable() generic accepts a data frame or a character vector of DBMS data types and creates a table in the database. It builds upon the existing sqlCreateTable() generic and also supports the temporary argument. If a table by that name already exists, an error is raised.\nThe new dbAppendTable() generic uses a prepared statement (created via sqlAppendTableTemplate()) to efficiently insert rows into the database. This avoids the internal overhead of converting values to SQL literals.\n\nThe following example shows the creation and population of a table with the new methods.\ntable_name\n\n## &lt;Id&gt; schema = my_schema, table = my_table\n\ndbRemoveTable(pg_conn, table_name, fail_if_missing = FALSE)\n\ndbCreateTable(pg_conn, table_name, c(a = \"int8\", b = \"float8\"))\n\ndbAppendTable(pg_conn, table_name, data.frame(a = 1:3, b = 1:3))\n\n## [1] 3\n\nstr(dbReadTable(pg_conn, table_name))\n\n## 'data.frame':    3 obs. of  2 variables:\n##  $ a:integer64 1 2 3 \n##  $ b: num  1 2 3\nThe dbWriteTable() methods in the three backends have been adapted to use the new methods."
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#support-for-64-bit-integers",
    "href": "blog/posts/dbi-2-final.html#support-for-64-bit-integers",
    "title": "Done “Establishing DBI”!?",
    "section": "Support for 64-bit integers",
    "text": "Support for 64-bit integers\nAs seen in the previous example, 64-bit integers can be read from the database. The three backends RSQLite, RPostgres and RMariaDB now also support writing 64-bit integers via the bit64 package:\ndata &lt;- data.frame(a = bit64::as.integer64(4:6), b = 4:6)\ndbAppendTable(pg_conn, table_name, data)\n\n## [1] 3\n\nstr(dbReadTable(pg_conn, table_name))\n\n## 'data.frame':    6 obs. of  2 variables:\n##  $ a:integer64 1 2 3 4 5 6 \n##  $ b: num  1 2 3 4 5 6\nBecause R still lacks support for native 64-bit integers, the bit64 package feels like the best compromise: the returned values can be computed on, or coerced to integer, numeric or even character depending on the application. In some cases, it may be useful to always coerce. This is where the new bigint argument to dbConnect() helps:\npg_conn_int &lt;- dbConnect(Postgres(), bigint = \"integer\")\nstr(dbReadTable(pg_conn_int, table_name))\n\n## 'data.frame':    6 obs. of  2 variables:\n##  $ a: int  1 2 3 4 5 6\n##  $ b: num  1 2 3 4 5 6\n\npg_conn_num &lt;- dbConnect(Postgres(), bigint = \"numeric\")\nstr(dbReadTable(pg_conn_num, table_name))\n\n## 'data.frame':    6 obs. of  2 variables:\n##  $ a: num  1 2 3 4 5 6\n##  $ b: num  1 2 3 4 5 6\n\npg_conn_chr &lt;- dbConnect(Postgres(), bigint = \"character\")\nstr(dbReadTable(pg_conn_chr, table_name))\n\n## 'data.frame':    6 obs. of  2 variables:\n##  $ a: chr  \"1\" \"2\" \"3\" \"4\" ...\n##  $ b: num  1 2 3 4 5 6\nThe bigint argument works consistently across the three backends RSQLite, RPostgres and RMariaDB, the DBI specification contains a test for and a description of the requirements."
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#geometry-columns",
    "href": "blog/posts/dbi-2-final.html#geometry-columns",
    "title": "Done “Establishing DBI”!?",
    "section": "Geometry columns",
    "text": "Geometry columns\nPostgreSQL has support for user-defined data types, this is used e.g. by PostGIS to store spatial data. Before, user-defined data types were returned as character values, with a warning. Thanks to a contribution by Etienne B. Racine:\n\nthe warnings are gone,\nthe user-defined data type is now stored in an attribute of the column in the data frame,\ndetails on columns with user-defined data types are available in dbColumnInfo().\n\n\ndbCreateTable(\n  pg_conn,\n  \"geom_test\",\n  c(id = \"int4\", geom = \"geometry(Point, 4326)\")\n)\n\ndata &lt;- data.frame(\n  id = 1,\n  geom = \"SRID=4326;POINT(-71.060316 48.432044)\",\n  stringsAsFactors = FALSE\n)\ndbAppendTable(pg_conn, \"geom_test\", data)\n\n## [1] 1\n\nstr(dbReadTable(pg_conn, \"geom_test\"))\n\n## 'data.frame':    1 obs. of  2 variables:\n##  $ id  : int 1\n##  $ geom:Class 'pq_geometry'  chr \"0101000020E61000003CDBA337DCC351C06D37C1374D374840\"\n\nres &lt;- dbSendQuery(pg_conn, \"SELECT * FROM geom_test\")\ndbColumnInfo(res)\n\n##   name      type   .oid .known .typname\n## 1   id   integer     23   TRUE     int4\n## 2 geom character 101529  FALSE geometry\n\ndbClearResult(res)\nSpecial support for geometry columns is currently available only in RPostgres."
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#duplicate-column-names",
    "href": "blog/posts/dbi-2-final.html#duplicate-column-names",
    "title": "Done “Establishing DBI”!?",
    "section": "Duplicate column names",
    "text": "Duplicate column names\nThe specification has been extended to disallow duplicate, empty or NA column names. The deduplication used by our three backends is similar to that used by tibble::set_tidy_names(), but the DBI specification does not require any particular deduplication mechanism. Syntactic names aren’t required either:\ndbGetQuery(sqlite_conn, \"SELECT 1, 2, 3\")\n\n##   1 2 3\n## 1 1 2 3\n\ndbGetQuery(sqlite_conn, \"SELECT 1 AS a, 2 AS a, 3 AS `a..2`\")\n\n##   a a..2 a..3\n## 1 1    2    3\n\ndbGetQuery(mariadb_conn, \"SELECT 1, 2, 3\")\n\n##   1 2 3\n## 1 1 2 3\n\ndbGetQuery(mariadb_conn, \"SELECT 1 AS a, 2 AS a, 3 AS `a..2`\")\n\n##   a a..2 a..3\n## 1 1    2    3\n\ndbGetQuery(pg_conn, \"SELECT 1, 2, 3\")\n\n##   ?column? ?column?..2 ?column?..3\n## 1        1           2           3\n\ndbGetQuery(pg_conn, 'SELECT 1 AS a, 2 AS a, 3 AS \"a..2\"')\n\n##   a a..2 a..3\n## 1 1    2    3"
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#helpers",
    "href": "blog/posts/dbi-2-final.html#helpers",
    "title": "Done “Establishing DBI”!?",
    "section": "Helpers",
    "text": "Helpers\nTwo little helper generics have been added.\nThe new dbIsReadOnly() generic (contributed by Anh Le) should return TRUE for a read-only connection. This is not part of the specification yet.\nThe dbCanConnect() tests a set of connection parameters. The default implementation simply connects and then disconnects upon success. For DBMS that can provide more efficient methods of checking connectivity, a lighter-weight implementation of this method may give a better experience.\nNone of the three backends currently provide specialized implementations for these generics."
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#code-reuse",
    "href": "blog/posts/dbi-2-final.html#code-reuse",
    "title": "Done “Establishing DBI”!?",
    "section": "Code reuse",
    "text": "Code reuse\nI have made some efforts to extract common C++ classes for assembling data frames and prepare them for reuse. The C++ source code for the three backends contains files prefixed with Db, these are almost identical across the backends. The planned packaging into the RKazam package had to yield to higher-priority features described above.\nThe situation in the R code is similar: I have found myself copy-pasting code from one backend into another because I didn’t feel it’s ready (or standardized enough) to be included in the DBI package.\nFor both use cases, a code reuse strategy based on copying/updating template files or reconciling files may be more robust than the traditional importing mechanisms offered by R."
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#outlook",
    "href": "blog/posts/dbi-2-final.html#outlook",
    "title": "Done “Establishing DBI”!?",
    "section": "Outlook",
    "text": "Outlook\nThe upcoming CRAN release of DBI, DBItest and the three backends RSQLite, RMariaDB and RPostgres are an important milestone. Stability is important when more and more users and projects use the new backends. Nevertheless, I see quite a few potential improvements that so far were out of scope of the “Improving DBI” and “Establishing DBI” projects:\n\nSupport running the test suite locally, to validate adherence to DBI for a particular installation.\nConsistent fast data import.\nConsistent query placeholders (currently $1 for RPostgres and ? for many other backends).\nSupport for arbitrary data types via hooks.\nAssistance with installation problems on specific architectures, or connectivity problems with certain databases, or other specific issues.\nRework the internal architecture of DBItest to simplify locating test failures.\nImprove the https://r-dbi.org website.\nNon-blocking queries.\n\nI have submitted another proposal to the R Consortium, hoping to receive support with these and other issues."
  },
  {
    "objectID": "blog/posts/dbi-2-final.html#acknowledgments",
    "href": "blog/posts/dbi-2-final.html#acknowledgments",
    "title": "Done “Establishing DBI”!?",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI’d like to thank the R Consortium for their generous financial support. Many thanks to the numerous contributors who helped make the past two projects a success."
  },
  {
    "objectID": "blog/posts/dbi-1-final.html",
    "href": "blog/posts/dbi-1-final.html",
    "title": "R-DBI",
    "section": "",
    "text": "The “Improving DBI” project, funded by the R consortium, started about a year ago. It includes\nBesides the established DBI and RSQLite packages, I have spent a lot of time on the new DBItest package. Final updates to these packages will be pushed to CRAN end of May this year, to give downstream maintainers some time to accommodate.\nThe follow-up project “Establishing DBI” will focus on fully DBI-compliant backends for MySQL/MariaDB and PostgreSQL, and on minor updates to the specs where appropriate."
  },
  {
    "objectID": "blog/posts/dbi-1-final.html#dbitest-specification",
    "href": "blog/posts/dbi-1-final.html#dbitest-specification",
    "title": "R-DBI",
    "section": "DBItest: Specification",
    "text": "DBItest: Specification\nA comprehensive backend-agnostic test suite for DBI backends is provided by the new DBItest package. When the project started, it was merely a collection of test cases. I have considerably expanded the test cases and provided a human-readable description for each, using literate programming techniques powered by roxygen2. The DBI package weaves these chunks of text to a single document that describes all test cases covered by the test suite, the textual DBI specification. This approach ensures that further updates to the specification are reflected in both the automatic tests and the text.\nThis package is aimed at backend implementers, who now can programmatically check with very little effort if their DBI backend conforms to the DBI specification. The verification can be integrated in the automated tests which are run as part of R’s package check mechanism in R CMD check. The odbc package, a new DBI-compliant interface to the ODBC interface, has been using DBItest from day one to enable test-driven development. The bigrquery package is another user of DBItest.\nBecause not all DBMS support all aspects of DBI, the DBItest package allows to restrict which parts of the specification are tested, or “tweak” certain aspects of the tests, e.g., the format of placeholders in parametrized queries. Adapting to other DBMS may require more work due to subtle differences in the implementation of SQL between various DBMS."
  },
  {
    "objectID": "blog/posts/dbi-1-final.html#dbi-definition",
    "href": "blog/posts/dbi-1-final.html#dbi-definition",
    "title": "R-DBI",
    "section": "DBI: Definition",
    "text": "DBI: Definition\nThis package has been around since 2001, it defines the actual DataBase Interface in R. I have taken over maintenance, and released versions 0.4-1, 0.5-1, and 0.6-1, with release of version 0.7 pending.\nThe most prominent change in this package is, of course, the textual DBI specification, which is included as an HTML vignette in the package. The documentation for the various methods defined by DBI is obtained directly from the specification. These help topics are combined in a sensible order to a single, self-contained document. This format is useful for both DBI users and implementers: users can look up the behavior of a method directly from its help page, and implementers can browse a comprehensive document that describes all aspects of the interface. I have also revised the description and the examples for all help topics.\nOther changes include:\n\nthe definition of new generics dbSendStatement() and dbExecute(), for backends that distinguish between queries that return a table and statements that manipulate data,\nthe new dbWithTransaction() generic and the dbBreak() helper function, thanks Barbara Borges Ribero,\nimproved or new default implementations for methods like dbGetQuery(), dbReadTable(), dbQuoteString(), dbQuoteIdentifier(),\ninternal changes that allow methods that don’t have a meaningful return value to return silently,\ntranslation of a helper function from C++ to R, to remove the dependency on Rcpp (thanks Hannes Mühleisen).\n\nFortunately, none of the changes seemed to have introduced any major regressions with downstream packages. The news contain a comprehensive list of changes."
  },
  {
    "objectID": "blog/posts/dbi-1-final.html#rsqlite-implementation",
    "href": "blog/posts/dbi-1-final.html#rsqlite-implementation",
    "title": "R-DBI",
    "section": "RSQLite: Implementation",
    "text": "RSQLite: Implementation\nRSQLite 1.1-2 is a complete rewrite of the original C implementation. Before focusing on compliance to the new DBI specification, it was important to assert compatibility to more than 100 packages on CRAN and Bioconductor that use RSQLite. These packages revealed many usage patterns that were difficult to foresee. Most of these usage patterns are supported in version 1.1-2, the more esoteric ones (such as supplying an integer where a logical is required) trigger a warning.\nSeveral rounds of “revdep checking” were necessary before most packages showed no difference in their check output compared to the original implementation. The downstream maintainers and the Bioconductor team were very supportive, and helped spotting functional and performance regressions during the release process. Two point releases were necessary to finally achieve a stable state.\nSupporting 64-bit integers also was trickier than anticipated. There is no built-in way to represent 64-bit integers in R. The bit64 package works around this limitation by using a numeric vector as storage, which also happens to use 8 bytes per element, and providing coercion functions. But when an integer column is fetched, it cannot be foreseen if a 64-bit value will occur in the result, and smaller integers must use R’s built-in integer type. For this purpose, an efficient data structure for collecting vectors, which is capable of changing the data type on the fly, has been implemented in C++. This data structure will be useful for many other DBI backends that need support for a 64-bit integer data type, and will be ported to the RKazam package in the follow-up project.\nOnce the DBI specification was completed, the process of making RSQLite compliant was easy: enable one of the disabled tests, fix the code, make sure all tests pass, rinse, and repeat. If you haven’t tried it, I seriosly recommend test-driven development, especially when the tests are already implemented.\nThe upcoming release of RSQLite 2.0 will require stronger adherence to the DBI specification also from callers. Where possible I tried to maintain backward compatibility, but in some cases breaks were inevitable because otherwise I’d have had to introduce far too many exceptions and corner cases in the DBI spec. For instance, row names are no longer included by default when writing or reading tables. The original behavior can be reenabled by calling pkgconfig::set_config(), so that packages or scripts that rely on row names continue to work as before. (The setting is active for the duration of the session, but only for the caller that has called pkgconfig::set_config().) I’m happy to include compatibility switches for other breaking changes if necessary and desired, to achieve both adherence to the specs and compatibility with existing behavior.\nA comprehensive list of changes can be found in the news."
  },
  {
    "objectID": "blog/posts/dbi-1-final.html#other-bits-and-pieces",
    "href": "blog/posts/dbi-1-final.html#other-bits-and-pieces",
    "title": "R-DBI",
    "section": "Other bits and pieces",
    "text": "Other bits and pieces\nThe RKazam package is a ready-to-use boilerplate for a DBI backend, named after the hypothetical DBMS used as example in a DBI vignette. It already “passes” all tests of the DBItest package, mostly by calling a function that skips the current test. Starting a DBI backend from scratch requires only copying and renaming the package’s code.\nR has limited support for time-of-day data. The hms package aims at filling this gap. It will be useful especially in the follow-up project, because SQLite doesn’t have an intrinsic type for time-of-day data, unlike many other DBMS."
  },
  {
    "objectID": "blog/posts/dbi-1-final.html#next-steps",
    "href": "blog/posts/dbi-1-final.html#next-steps",
    "title": "R-DBI",
    "section": "Next steps",
    "text": "Next steps\nThe ensemble CRAN release of the three packages DBI, DBItest and RSQLite will occur in parallel to the startup phase for the “Establishing DBI” follow-up project. This project consists of:\n\nFully DBI compatible backends for MySQL/MariaDB and Postgres\nA backend-agnostic C++ data structure to collect column data in the RKazam package\nSupport for spatial data\n\nIn addition, it will contain an update to the DBI specification, mostly concerning support for schemas and for querying the structure of the table returned for a query. Targeting three DBMS instead of one will help properly specify these two particularly tricky parts of DBI. I’m happy to take further feedback from users and backend implementers towards further improvement of the DBI specification."
  },
  {
    "objectID": "blog/posts/dbi-1-final.html#acknowledgments",
    "href": "blog/posts/dbi-1-final.html#acknowledgments",
    "title": "R-DBI",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nMany thanks to the R Consortium, who has sponsored this project, and to the many contributors who have spotted problems, suggested improvements, submitted pull requests, or otherwise helped make this project a great success. In particular, I’d like to thank Hadley Wickham, who suggested the idea, supported initial development of the DBItest package, and provided helpful feedback; and Christoph Hösler, Hannes Mühleisen, Imanuel Costigan, Jim Hester, Marcel Boldt, and @thrasibule for using it and contributing to it. I enjoyed working on this project, looking forward to “Establishing DBI”!"
  }
]